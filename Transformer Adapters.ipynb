{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-XTIOLv0isn"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ju-alwbHmKYA",
    "outputId": "1964c7fb-4c35-411a-f516-6faf5064996b",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 3.4 MB/s \n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.41.1\n",
      "    Uninstalling tqdm-4.41.1:\n",
      "      Successfully uninstalled tqdm-4.41.1\n",
      "Successfully installed tqdm-4.61.2\n",
      "Collecting adapter-transformers\n",
      "  Downloading adapter_transformers-2.1.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 9.1 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub>=0.0.13\n",
      "  Downloading huggingface_hub-0.0.14-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (4.6.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (1.19.5)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 52.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (2.23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (2019.12.20)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (3.13)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 56.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (4.61.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from adapter-transformers) (21.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.13->adapter-transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->adapter-transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->adapter-transformers) (3.5.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->adapter-transformers) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->adapter-transformers) (1.0.1)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, adapter-transformers\n",
      "Successfully installed adapter-transformers-2.1.1 huggingface-hub-0.0.14 sacremoses-0.0.45 tokenizers-0.10.3\n",
      "Collecting datasets\n",
      "  Downloading datasets-1.10.2-py3-none-any.whl (542 kB)\n",
      "\u001b[K     |████████████████████████████████| 542 kB 9.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.61.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "\u001b[K     |████████████████████████████████| 243 kB 19.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
      "Collecting fsspec>=2021.05.0\n",
      "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
      "\u001b[K     |████████████████████████████████| 118 kB 20.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.14)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: xxhash, fsspec, datasets\n",
      "Successfully installed datasets-1.10.2 fsspec-2021.7.0 xxhash-2.0.2\n",
      "Collecting optuna\n",
      "  Downloading optuna-2.8.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 9.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.61.2)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.8.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 8.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
      "Collecting alembic\n",
      "  Downloading alembic-1.6.5-py2.py3-none-any.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 16.5 MB/s \n",
      "\u001b[?25hCollecting colorlog\n",
      "  Downloading colorlog-5.0.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.6.1)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 5.0 MB/s \n",
      "\u001b[?25hCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-3.3.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 6.9 MB/s \n",
      "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 20.7 MB/s \n",
      "\u001b[?25hCollecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.1.2-py3-none-any.whl (141 kB)\n",
      "\u001b[K     |████████████████████████████████| 141 kB 17.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
      "Collecting colorama>=0.3.7\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=35b5ba2909d4d82cc693ccbfd1cb482081a20969a943fd867d47c88b7f4513bc\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyperclip, pbr, colorama, stevedore, python-editor, Mako, cmd2, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed Mako-1.1.4 alembic-1.6.5 cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-5.0.1 optuna-2.8.0 pbr-5.6.0 pyperclip-1.8.2 python-editor-1.0.4 stevedore-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tqdm\n",
    "!pip install -U adapter-transformers\n",
    "!pip install -U datasets\n",
    "!pip install -U optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNlfuDPiiC-R",
    "outputId": "77192b71-0b1c-4f15-9223-ad79e426e86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 28 05:56:32 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iY3WETIAiJ_w",
    "outputId": "5f392f0a-9140-41e5-e437-ce40ac99e9b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 13.6 gigabytes of available RAM\n",
      "\n",
      "To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"\n",
      "menu, and then select High-RAM in the Runtime shape dropdown. Then, \n",
      "re-execute this cell.\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
    "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
    "  print('re-execute this cell.')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Mx916lBCfoL"
   },
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYHRQKkM5xhl",
    "outputId": "41215239-a178-420c-e36f-9fbb7ca5fa89",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2\n",
      "1.9.0+cu102\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_metric\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import numpy as np\n",
    "import transformers\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction\n",
    "\n",
    "print(datasets.__version__)\n",
    "print(torch.__version__)\n",
    "\n",
    "#datasets.list_datasets()\n",
    "#dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "50f0b3371e834a1591d7f70ac59e7c15",
      "d2072088e73a4b83986c1a0e3ab74e41",
      "b74e2bd34ee74ebb8ceb3f737d06d7bb",
      "a5eb95fdc69643748371865f154157ad",
      "7351c1907ef0419f80b99827b82edd3a",
      "c3ee78a3a0674f88acb288b03caf72a0",
      "bbf1694751084898933782ef82b11b54",
      "9bebfd4ce4154bbba6f59bf956585444",
      "140897f351bc419e9c135cae1a3d1166",
      "e760f211c30b4efdbc91aa8d6c230d72",
      "35ef00dd622846279bd8f08d28ca74b3",
      "850e0c86d61344c4906d3668a3027f23",
      "dab717c51b0f42898fc5db0bff734f71",
      "4205dd8cbdcd4ead95daae37b707b3a7",
      "4122646551fa409a812a8be07c9a184e",
      "26a8c094120142858b62d4c4a5578fc7",
      "a338142858c04a2ca7846f921a738adf",
      "d0d26e0e94c840e486436fea1827a1cb",
      "7a3e1e6d289a4e98ab6e8ce9cf7d3d5d",
      "15e8d4a201294c03bcec616ac5b1da84",
      "5b788c8b1fa04cfa85889d879fbede28",
      "dfd3fed14b2f41d2a436376d8259ae70",
      "f00ecbf1021d4070875a835bc30c5bf8",
      "08a4df9610774f6782677ba56ebab58e",
      "40d062cfa37f44ea8e1ecfc4d7075882",
      "2edf747c338a499b8240e23161aad905",
      "1e6160ca450e428fbb2143a682fb3434",
      "b0d4fc141fc548d5aa920b9c926a622c",
      "c026bde83e884f13b52f0e4cc759aa8f",
      "438beab006584f9a9612033e8771d61c",
      "3d4f01d5693e45e2ae8e9389652b2931",
      "f52250017101446c935a42cdf56e4f97",
      "8ef366e7d9ff4667aceacd05d51603fa",
      "dcb632c0ecb94873971f7ffaf3b81351",
      "98c3500d507b466aa0d3b4a6cc740050",
      "c5a1aa5a330e4b58af6f3fac09ce84d1",
      "810c58dac58745f69bae94bff1d25ac1",
      "7bb05c7d061f4e5d946b3d687b0b1da3",
      "a6507f52e92446a19f9cb6a851222010",
      "7dbff33dab6c4b3986ec980966a32102",
      "e06215f4f39f46b4a6724aa6ed186d79",
      "e16d12ce16a8426f87e2e3ff76088526",
      "22747cfdd91b4f75beb7cea08049a98b",
      "7d614be28733434e822c8c94e6afbc68",
      "80d64d4715e240aa891680d9f5fbf2d5",
      "236d318b5e294b5d90a45be919cb7b28",
      "6a61a09f496e432db1de5eadd5dc893d",
      "c11f4e959f2c4cc98134926576482148",
      "6e734b4ab15545d3bb71e1cc12f87185",
      "3d3c2023664840ad841af91c123b9e18",
      "feec269c060e45d0949c5359e364c8fe",
      "900ebdf4023d41feb5e179c75f10a1af",
      "d86fb42dac68454f8c1a8d1dce6e5902",
      "cd926cc895834ab99696560801d692ad",
      "87f9d2b4d6ad414da7c45e80b1a29b46",
      "01422aa981ac499ab42a2780d472fef4",
      "c4136a59564c4e6fad94ccf6de8d2d91",
      "10f9f29ad5d34645abdc6d7d420449e2",
      "4147e65bd76a47398a9796935dc9e37e",
      "a18b73f3d7344597a0ec367ce8904b3e",
      "afd5c79532164bc2b2d7779da2e6c415",
      "79039490ffb6485fb81bbf9c2400e4e8",
      "de844acc43a642bfb25f367e5abd0a43",
      "cc1c445aea0b48d19e6f89e65b34a54a",
      "7edc6b8e508f49f9a71521c425b1d222",
      "df9f8ec638df4def8c4658fbb3238aa5",
      "505071ff7b1842d69af1ca5db0d740f6",
      "03d8a43b86de4043b92555d85dda97bc",
      "3beb8070a0ef4bf195bfce6697152a4f",
      "0a04dc88185d4527901b6552ffd0d7b9",
      "e6f0cd88d2fb4402b0a6201b9a8c21e9",
      "a40cd83020454745a4ae8e83309ede06",
      "12692bf8d59a4deca35ddbdecfceec51",
      "de9721593e554494948ba89ff75cba34",
      "557f2665e9a440b795b0dea7af31dd0d",
      "6b5e7fccad2d450583789e28b143ff13",
      "421ba42a48874ef4bdc01d2ff3ed44d0"
     ]
    },
    "id": "7NNCV_R7h1Uj",
    "outputId": "5942bb80-a45e-4462-ca05-fcaf48a4904f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f0b3371e834a1591d7f70ac59e7c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/7.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850e0c86d61344c4906d3668a3027f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/cola (download: 368.14 KiB, generated: 596.73 KiB, post-processed: Unknown size, total: 964.86 KiB) to /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00ecbf1021d4070875a835bc30c5bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/377k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb632c0ecb94873971f7ffaf3b81351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d64d4715e240aa891680d9f5fbf2d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01422aa981ac499ab42a2780d472fef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505071ff7b1842d69af1ca5db0d740f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 8551\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('glue', 'cola')\n",
    "metric = load_metric('glue', 'cola')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8B4MRXqnh1Uk",
    "outputId": "1265dd11-49a0-4913-ec93-e62384cbd8d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 28, 25]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[max([s['sentence'].count(' ') for s in dataset[d]]) for d in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "e298623774404366b574c04ee1aa1038",
      "b2b544a7292141bb926386efd5be9919",
      "4d0f14c2776a4f398f2b960a6bab9e08",
      "a2b1a537be4f4d3080d4e18eb77fe111",
      "737d6ffabe94483793795681362c90cb",
      "42b604dab2d64d29b10602d44c99a7f7",
      "86c755818d1049ca971a6819438ac83a",
      "34521e8b90c5403f8bd22d498c79e329",
      "77032b279a4d49faa643c45d537a6c19",
      "025962ebb1484f428fa45f030f55fecf",
      "8ad3bcb3016946c2a2ba6524ba2c7c33",
      "144e8c60dc104f59977f611f78ac66a2",
      "d3e4cb7567e740899e124a079e6a8c11",
      "03fb36553e7c476e9211e660d36e223e",
      "e0dbbc0fe8b847c490a2a76c125b0cbe",
      "b7d66d2d10924e81bf0291e4d3641471",
      "051d98db5e4a465d96535220d98c15b2",
      "ab35a88f0fa54acfb268c3b2dafc78f1",
      "655ef14346da45a687a47d34ee18c70b",
      "2457b9477dd644bb9172920f76ae6c92",
      "e3f956bacf334ed28b513f0ba3312d90",
      "d768b73cf220455f992e417b59f7dbc3",
      "09997ec0422642029df6971cc1a65882",
      "60f6473abe214982a82859824f1995ad",
      "6c33e7d5aba34cdfb612cb4503698109",
      "0149351d203a4325b11e362ff54695f3",
      "29b8234e8bfa447581b4e60a337b8140",
      "035c10c20ebf46a5a34fc7e89aaab084",
      "89a33410bc114f0e8598a468d1e59bd2",
      "d6772c7b6fa0415a9bbfcf2c947a6870",
      "e3f1083b462d4851bf4028e525a3a1f3",
      "e3ea65c9888d45ac9ab21c6c309d6d3a",
      "6dc894e4a3eb437db5afb0a794ca4d35",
      "6702268d3a74406e8746dc12e3066a7d",
      "248136f951a545a99274a4ea556172f2",
      "2b1ce1e1628642ebbfe6e571ad9f3407",
      "ce87cd6b3b0146d996c440669a8c93ec",
      "4651a1be2ad347d3b9636a7c008915e9",
      "b27233507a1b4fa5a7215ba01c3abf86",
      "12986320205e410c9e9eb58802cd686d",
      "ec57dac55cda461182c988fff726fe54",
      "ca4c8c62f8e2486f820cbb5c6d09c81d",
      "909b9b1535364e889084c5ca187323e2",
      "38d3eebc537e4d6893276ae010581470"
     ]
    },
    "id": "_xdVDIc58O6g",
    "outputId": "c8c1725b-a6eb-488b-c881-0f68ffa078f5",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e298623774404366b574c04ee1aa1038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144e8c60dc104f59977f611f78ac66a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09997ec0422642029df6971cc1a65882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6702268d3a74406e8746dc12e3066a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: rename_column_ is deprecated and will be removed in the next major version of datasets. Use DatasetDict.rename_column instead.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, AutoTokenizer, AutoModelWithHeads, RobertaConfig, RobertaModelWithHeads, AutoConfig\n",
    "\n",
    "model_name = \"roberta-base\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def encode_batch(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(batch[\"sentence\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "\n",
    "# Encode the input data\n",
    "dataset = dataset.map(encode_batch, batched=True, num_proc=2)\n",
    "# The transformers model expects the target class column to be named \"labels\"\n",
    "dataset.rename_column_(\"label\", \"labels\")\n",
    "# Transform to pytorch tensors and only output the required columns\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7fjcJvm2Z9v"
   },
   "outputs": [],
   "source": [
    "#np.unique(np.array([d['labels'].numpy() for d in dataset['test']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2-2CbfPGYvi"
   },
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tp9uG-pT-qgv",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# from transformers import RobertaConfig, RobertaModelWithHeads\n",
    "\n",
    "# config = RobertaConfig.from_pretrained(\n",
    "#     \"roberta-base\",\n",
    "#     num_labels=2,\n",
    "# )\n",
    "# model = RobertaModelWithHeads.from_pretrained(\n",
    "#     \"roberta-base\",\n",
    "#     config=config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzQ-QnSTqpnw"
   },
   "outputs": [],
   "source": [
    "# config = AutoConfig.from_pretrained(model_name, num_labels=2)\n",
    "# model = AutoModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "# adapter_config = transformers.PfeifferConfig(reduction_factor=32)\n",
    "# model.add_adapter(\"cola\", config=adapter_config)\n",
    "# model.add_classification_head(\"cola\", num_labels=2)\n",
    "# model.train_adapter(\"cola\")\n",
    "# model.load_adapter(\"lingaccept/cola@ukp\", config='houlsby')\n",
    "# model.set_active_adapters(\"cola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xk6pt1yWvy28"
   },
   "outputs": [],
   "source": [
    "#model.get_adapter('cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXCPDz2t2A4w"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p: EvalPrediction):\n",
    "    \n",
    "   preds = np.argmax(p.predictions, axis=1)\n",
    "   acc = (preds == p.label_ids).mean()\n",
    "   mat = metrics.matthews_corrcoef(p.label_ids, preds)\n",
    "   f1 = metrics.f1_score(p.label_ids, preds)\n",
    "   #corr = np.corrcoef(p.label_ids)\n",
    "\n",
    "   #return {\"acc\": acc, \"matthews_corr\": mat, \"F1\":f1}\n",
    "   return metric.compute(predictions=preds, references= p.label_ids)\n",
    "   #return {\"matthews_corr\": mat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FRft_5AAlQd",
    "outputId": "50efd653-45a1-423e-c193-80cb85efbf81",
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "def model_init():\n",
    "    \n",
    "    config = AutoConfig.from_pretrained(model_name, num_labels=2)\n",
    "    model = AutoModelWithHeads.from_pretrained(model_name, config=config)\n",
    "    \n",
    "    adapter_config = transformers.PfeifferConfig(reduction_factor=128)\n",
    "    model.add_adapter(\"cola\", config=adapter_config)\n",
    "    model.add_classification_head(\"cola\", num_labels=2)\n",
    "    model.train_adapter(\"cola\")\n",
    "    return model\n",
    "\n",
    "def hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True),\n",
    "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 3, 20),\n",
    "        #\"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
    "        #\"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16, 32, 64]),\n",
    "    }\n",
    "\n",
    "# def hp_space(trial):\n",
    "#     from ray import tune\n",
    "\n",
    "#     return {\n",
    "#         \"learning_rate\": tune.loguniform(1e-5, 1e-3),\n",
    "#         \"num_train_epochs\": tune.choice(range(3, 15)),\n",
    "#         #\"seed\": tune.choice(range(1, 41)),\n",
    "#         \"per_device_train_batch_size\": tune.choice([4, 8, 16, 32, 64]),\n",
    "#     }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    #learning_rate=1e-4,\n",
    "    #num_train_epochs=6,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    #evaluate_during_training=True, \n",
    "    evaluation_strategy = 'epoch',\n",
    "    #eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    output_dir=\"./training_output\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "#model = model_init()\n",
    "trainer = Trainer(\n",
    "    #model=model,\n",
    "    args=training_args,\n",
    "    #tokenizer=tokenizer,\n",
    "    model_init = model_init,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0peL81Eh1Up"
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "# del trainer\n",
    "\n",
    "# import gc\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DFlj8UZQh1Up",
    "outputId": "b17e0a9b-ef61-4b74-c27c-d34a40b755df",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-22 18:32:12,851]\u001b[0m A new study created in memory with name: no-name-3e405697-a0cd-4f91-8f41-dc045d8f0c11\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1876\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1876' max='1876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1876/1876 09:02, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.502003</td>\n",
       "      <td>0.436016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.424575</td>\n",
       "      <td>0.550860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.492637</td>\n",
       "      <td>0.482941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.483069</td>\n",
       "      <td>0.542267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.435804</td>\n",
       "      <td>0.552078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.434557</td>\n",
       "      <td>0.557276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.445198</td>\n",
       "      <td>0.563783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-0/checkpoint-500\n",
      "Configuration saved in ./training_output/run-0/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-0/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-0/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-0/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-0/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-0/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-0/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-0/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-0/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-0/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-0/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-0/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-0/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-0/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-0/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-0/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-0/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-0/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-0/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-0/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 18:41:18,966]\u001b[0m Trial 0 finished with value: 0.5637833320596455 and parameters: {'learning_rate': 0.0002052814523240765, 'num_train_epochs': 7}. Best is trial 0 with value: 0.5637833320596455.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4288' max='4288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4288/4288 20:39, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.610655</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.607400</td>\n",
       "      <td>0.576608</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.607400</td>\n",
       "      <td>0.501245</td>\n",
       "      <td>0.388716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>0.526842</td>\n",
       "      <td>0.392702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>0.498360</td>\n",
       "      <td>0.452422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.450800</td>\n",
       "      <td>0.483901</td>\n",
       "      <td>0.461206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.450800</td>\n",
       "      <td>0.494376</td>\n",
       "      <td>0.466549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.465774</td>\n",
       "      <td>0.498168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.486785</td>\n",
       "      <td>0.472390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>0.494389</td>\n",
       "      <td>0.472390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.424400</td>\n",
       "      <td>0.505919</td>\n",
       "      <td>0.460870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.409300</td>\n",
       "      <td>0.483100</td>\n",
       "      <td>0.494643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.409300</td>\n",
       "      <td>0.490420</td>\n",
       "      <td>0.483632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.401500</td>\n",
       "      <td>0.482710</td>\n",
       "      <td>0.486351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>0.479060</td>\n",
       "      <td>0.486709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>0.480258</td>\n",
       "      <td>0.486709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "Saving model checkpoint to ./training_output/run-1/checkpoint-500\n",
      "Configuration saved in ./training_output/run-1/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-1/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-1/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-1/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-1/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-1/checkpoint-2000\n",
      "Configuration saved in ./training_output/run-1/checkpoint-2000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-2000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-1/checkpoint-2500\n",
      "Configuration saved in ./training_output/run-1/checkpoint-2500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-2500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-1/checkpoint-3000\n",
      "Configuration saved in ./training_output/run-1/checkpoint-3000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-3000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-1/checkpoint-3500\n",
      "Configuration saved in ./training_output/run-1/checkpoint-3500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-3500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-1/checkpoint-4000\n",
      "Configuration saved in ./training_output/run-1/checkpoint-4000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-4000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-1/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-1/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 19:02:02,258]\u001b[0m Trial 1 finished with value: 0.4867092923459376 and parameters: {'learning_rate': 4.0351243929106616e-05, 'num_train_epochs': 16}. Best is trial 0 with value: 0.5637833320596455.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4288' max='4288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4288/4288 20:37, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.494711</td>\n",
       "      <td>0.441442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.412123</td>\n",
       "      <td>0.552091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.500700</td>\n",
       "      <td>0.478383</td>\n",
       "      <td>0.501933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.405100</td>\n",
       "      <td>0.461658</td>\n",
       "      <td>0.555443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.405100</td>\n",
       "      <td>0.458206</td>\n",
       "      <td>0.557414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.429926</td>\n",
       "      <td>0.582258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.365500</td>\n",
       "      <td>0.403069</td>\n",
       "      <td>0.568625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.404979</td>\n",
       "      <td>0.582787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.469470</td>\n",
       "      <td>0.570137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.438293</td>\n",
       "      <td>0.582515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.420568</td>\n",
       "      <td>0.575978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.481766</td>\n",
       "      <td>0.572681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.503440</td>\n",
       "      <td>0.575804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.451182</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.457493</td>\n",
       "      <td>0.571118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.462840</td>\n",
       "      <td>0.573350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-2/checkpoint-500\n",
      "Configuration saved in ./training_output/run-2/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-2/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-2/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-2/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-2/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-2/checkpoint-2000\n",
      "Configuration saved in ./training_output/run-2/checkpoint-2000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-2000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-2/checkpoint-2500\n",
      "Configuration saved in ./training_output/run-2/checkpoint-2500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-2500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-2/checkpoint-3000\n",
      "Configuration saved in ./training_output/run-2/checkpoint-3000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-3000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-2/checkpoint-3500\n",
      "Configuration saved in ./training_output/run-2/checkpoint-3500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-3500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-2/checkpoint-4000\n",
      "Configuration saved in ./training_output/run-2/checkpoint-4000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-4000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-2/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-2/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 19:22:42,932]\u001b[0m Trial 2 finished with value: 0.5733495702281163 and parameters: {'learning_rate': 0.00020558469588589345, 'num_train_epochs': 16}. Best is trial 2 with value: 0.5733495702281163.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 13\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3484\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3484' max='3484' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3484/3484 16:45, Epoch 13/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.482267</td>\n",
       "      <td>0.469245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.406047</td>\n",
       "      <td>0.550008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.491700</td>\n",
       "      <td>0.467647</td>\n",
       "      <td>0.517939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.461536</td>\n",
       "      <td>0.563208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.466034</td>\n",
       "      <td>0.552318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.356800</td>\n",
       "      <td>0.432738</td>\n",
       "      <td>0.570636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.356800</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.577127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.414209</td>\n",
       "      <td>0.566828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.468007</td>\n",
       "      <td>0.560198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.444970</td>\n",
       "      <td>0.574092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.440116</td>\n",
       "      <td>0.568736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.465627</td>\n",
       "      <td>0.562907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.460050</td>\n",
       "      <td>0.562907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-3/checkpoint-500\n",
      "Configuration saved in ./training_output/run-3/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-3/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-3/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-3/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-3/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-3/checkpoint-2000\n",
      "Configuration saved in ./training_output/run-3/checkpoint-2000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-2000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-3/checkpoint-2500\n",
      "Configuration saved in ./training_output/run-3/checkpoint-2500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-2500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-3/checkpoint-3000\n",
      "Configuration saved in ./training_output/run-3/checkpoint-3000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-3000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-3/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-3/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 19:39:31,273]\u001b[0m Trial 3 finished with value: 0.5629066123861417 and parameters: {'learning_rate': 0.00024396432276595098, 'num_train_epochs': 13}. Best is trial 2 with value: 0.5733495702281163.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1876\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1876' max='1876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1876/1876 08:59, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.614208</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.612601</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.610751</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.606300</td>\n",
       "      <td>0.609479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.606300</td>\n",
       "      <td>0.608384</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.603700</td>\n",
       "      <td>0.607902</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.603700</td>\n",
       "      <td>0.607474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "Saving model checkpoint to ./training_output/run-4/checkpoint-500\n",
      "Configuration saved in ./training_output/run-4/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-4/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-4/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-4/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-4/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-4/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-4/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-4/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-4/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-4/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-4/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-4/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-4/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-4/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-4/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-4/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-4/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-4/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-4/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-4/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 19:48:34,587]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'learning_rate': 1.3946588910919733e-05, 'num_train_epochs': 7}. Best is trial 2 with value: 0.5733495702281163.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 11\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2948\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='537' max='2948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 537/2948 02:29 < 11:13, 3.58 it/s, Epoch 2/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.485274</td>\n",
       "      <td>0.452506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.496400</td>\n",
       "      <td>0.412874</td>\n",
       "      <td>0.546341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-5/checkpoint-500\n",
      "Configuration saved in ./training_output/run-5/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-5/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-5/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-5/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-5/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-5/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-07-22 19:51:12,290]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 804\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='537' max='804' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [537/804 02:29 < 01:14, 3.58 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.472178</td>\n",
       "      <td>0.491202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481700</td>\n",
       "      <td>0.423499</td>\n",
       "      <td>0.529454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-6/checkpoint-500\n",
      "Configuration saved in ./training_output/run-6/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-6/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-6/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-6/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-6/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-6/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-07-22 19:53:49,806]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 13\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3484\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3484' max='3484' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3484/3484 16:45, Epoch 13/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.448028</td>\n",
       "      <td>0.514215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.393287</td>\n",
       "      <td>0.577469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.462383</td>\n",
       "      <td>0.531416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.436935</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.474680</td>\n",
       "      <td>0.559928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>0.405898</td>\n",
       "      <td>0.606040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.335900</td>\n",
       "      <td>0.403464</td>\n",
       "      <td>0.609780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.399745</td>\n",
       "      <td>0.610270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.452103</td>\n",
       "      <td>0.578479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.275800</td>\n",
       "      <td>0.449925</td>\n",
       "      <td>0.588697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.275800</td>\n",
       "      <td>0.437022</td>\n",
       "      <td>0.605467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.475118</td>\n",
       "      <td>0.580473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.478216</td>\n",
       "      <td>0.578090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-7/checkpoint-500\n",
      "Configuration saved in ./training_output/run-7/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-7/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-7/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-7/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-7/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-7/checkpoint-2000\n",
      "Configuration saved in ./training_output/run-7/checkpoint-2000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-2000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-7/checkpoint-2500\n",
      "Configuration saved in ./training_output/run-7/checkpoint-2500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-2500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-7/checkpoint-3000\n",
      "Configuration saved in ./training_output/run-7/checkpoint-3000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-3000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-7/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-7/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 20:10:37,921]\u001b[0m Trial 7 finished with value: 0.5780903072486336 and parameters: {'learning_rate': 0.0003616094796607866, 'num_train_epochs': 13}. Best is trial 7 with value: 0.5780903072486336.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 11\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2948\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2948' max='2948' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2948/2948 14:14, Epoch 11/11]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.447260</td>\n",
       "      <td>0.531778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>0.383826</td>\n",
       "      <td>0.574668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>0.452098</td>\n",
       "      <td>0.539283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.470869</td>\n",
       "      <td>0.571067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.534386</td>\n",
       "      <td>0.585706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>0.419742</td>\n",
       "      <td>0.611877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.290200</td>\n",
       "      <td>0.433192</td>\n",
       "      <td>0.601244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.421149</td>\n",
       "      <td>0.631991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.482357</td>\n",
       "      <td>0.614029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.520757</td>\n",
       "      <td>0.628160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.205200</td>\n",
       "      <td>0.547532</td>\n",
       "      <td>0.625667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-8/checkpoint-500\n",
      "Configuration saved in ./training_output/run-8/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-8/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-8/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-8/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-8/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-8/checkpoint-2000\n",
      "Configuration saved in ./training_output/run-8/checkpoint-2000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-2000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-8/checkpoint-2500\n",
      "Configuration saved in ./training_output/run-8/checkpoint-2500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-2500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-8/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-8/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 20:24:55,382]\u001b[0m Trial 8 finished with value: 0.6256673855627156 and parameters: {'learning_rate': 0.0009384872319244253, 'num_train_epochs': 11}. Best is trial 8 with value: 0.6256673855627156.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 9\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2412\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='269' max='2412' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 269/2412 01:12 < 09:39, 3.70 it/s, Epoch 1/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.567382</td>\n",
       "      <td>0.080368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-07-22 20:26:15,563]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1340' max='1340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1340/1340 06:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.443917</td>\n",
       "      <td>0.506990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>0.385669</td>\n",
       "      <td>0.602809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>0.461092</td>\n",
       "      <td>0.531202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.442473</td>\n",
       "      <td>0.575770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.354900</td>\n",
       "      <td>0.427774</td>\n",
       "      <td>0.576256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-10/checkpoint-500\n",
      "Configuration saved in ./training_output/run-10/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-10/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-10/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-10/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-10/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-10/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-10/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-10/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-10/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-10/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-10/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-10/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-10/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 20:32:46,359]\u001b[0m Trial 10 finished with value: 0.5762564573315502 and parameters: {'learning_rate': 0.0009122522058574567, 'num_train_epochs': 5}. Best is trial 8 with value: 0.6256673855627156.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 19\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='537' max='5092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 537/5092 02:30 < 21:18, 3.56 it/s, Epoch 2/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.467663</td>\n",
       "      <td>0.493879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>0.417962</td>\n",
       "      <td>0.551456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-11/checkpoint-500\n",
      "Configuration saved in ./training_output/run-11/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-11/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-11/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-11/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-11/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-11/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-07-22 20:35:24,481]\u001b[0m Trial 11 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 13\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3484\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3484' max='3484' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3484/3484 16:47, Epoch 13/13]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.442725</td>\n",
       "      <td>0.546584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>0.405657</td>\n",
       "      <td>0.561713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>0.443300</td>\n",
       "      <td>0.549613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>0.462383</td>\n",
       "      <td>0.554667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.370100</td>\n",
       "      <td>0.504478</td>\n",
       "      <td>0.565194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.314200</td>\n",
       "      <td>0.397316</td>\n",
       "      <td>0.606040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.314200</td>\n",
       "      <td>0.385629</td>\n",
       "      <td>0.616493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.276900</td>\n",
       "      <td>0.390619</td>\n",
       "      <td>0.598713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.276900</td>\n",
       "      <td>0.453894</td>\n",
       "      <td>0.593787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.508916</td>\n",
       "      <td>0.593281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.434575</td>\n",
       "      <td>0.610270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>0.479229</td>\n",
       "      <td>0.590741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>0.502814</td>\n",
       "      <td>0.577995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-12/checkpoint-500\n",
      "Configuration saved in ./training_output/run-12/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-12/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-12/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-12/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-12/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-12/checkpoint-2000\n",
      "Configuration saved in ./training_output/run-12/checkpoint-2000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-2000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-12/checkpoint-2500\n",
      "Configuration saved in ./training_output/run-12/checkpoint-2500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-2500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-12/checkpoint-3000\n",
      "Configuration saved in ./training_output/run-12/checkpoint-3000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-3000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-12/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-12/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 20:52:15,002]\u001b[0m Trial 12 finished with value: 0.5779953180551635 and parameters: {'learning_rate': 0.0005856039812206535, 'num_train_epochs': 13}. Best is trial 8 with value: 0.6256673855627156.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 16\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4288' max='4288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4288/4288 20:44, Epoch 16/16]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.446118</td>\n",
       "      <td>0.527953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>0.398717</td>\n",
       "      <td>0.574538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.468900</td>\n",
       "      <td>0.447384</td>\n",
       "      <td>0.549816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.512432</td>\n",
       "      <td>0.557865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.553769</td>\n",
       "      <td>0.539699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.415573</td>\n",
       "      <td>0.613311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.422714</td>\n",
       "      <td>0.625157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.367757</td>\n",
       "      <td>0.625110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.447673</td>\n",
       "      <td>0.606302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>0.479623</td>\n",
       "      <td>0.606633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.248900</td>\n",
       "      <td>0.414023</td>\n",
       "      <td>0.639959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.543471</td>\n",
       "      <td>0.614070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.590662</td>\n",
       "      <td>0.607603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.492166</td>\n",
       "      <td>0.630656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.508587</td>\n",
       "      <td>0.635655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.517978</td>\n",
       "      <td>0.626133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-13/checkpoint-500\n",
      "Configuration saved in ./training_output/run-13/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-13/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-13/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-13/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-13/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-13/checkpoint-2000\n",
      "Configuration saved in ./training_output/run-13/checkpoint-2000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-2000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-13/checkpoint-2500\n",
      "Configuration saved in ./training_output/run-13/checkpoint-2500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-2500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-13/checkpoint-3000\n",
      "Configuration saved in ./training_output/run-13/checkpoint-3000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-3000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-13/checkpoint-3500\n",
      "Configuration saved in ./training_output/run-13/checkpoint-3500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-3500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-13/checkpoint-4000\n",
      "Configuration saved in ./training_output/run-13/checkpoint-4000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-4000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-13/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-13/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 21:13:02,971]\u001b[0m Trial 13 finished with value: 0.6261333902108016 and parameters: {'learning_rate': 0.0005286473835231663, 'num_train_epochs': 16}. Best is trial 13 with value: 0.6261333902108016.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 19\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5092' max='5092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5092/5092 24:38, Epoch 19/19]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.459823</td>\n",
       "      <td>0.529477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.447954</td>\n",
       "      <td>0.563783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.435102</td>\n",
       "      <td>0.554796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>0.512081</td>\n",
       "      <td>0.567550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>0.509071</td>\n",
       "      <td>0.560198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.395202</td>\n",
       "      <td>0.609351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.431921</td>\n",
       "      <td>0.625760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.383295</td>\n",
       "      <td>0.624801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.513386</td>\n",
       "      <td>0.604496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.561849</td>\n",
       "      <td>0.605713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.527390</td>\n",
       "      <td>0.623631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.609284</td>\n",
       "      <td>0.588054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.625298</td>\n",
       "      <td>0.580530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>0.663934</td>\n",
       "      <td>0.611508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.680318</td>\n",
       "      <td>0.600697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>0.675402</td>\n",
       "      <td>0.621954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.643233</td>\n",
       "      <td>0.628771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.685618</td>\n",
       "      <td>0.633768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.104900</td>\n",
       "      <td>0.722384</td>\n",
       "      <td>0.628634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-500\n",
      "Configuration saved in ./training_output/run-14/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-14/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-14/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-2000\n",
      "Configuration saved in ./training_output/run-14/checkpoint-2000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-2000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-2500\n",
      "Configuration saved in ./training_output/run-14/checkpoint-2500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-2500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-3000\n",
      "Configuration saved in ./training_output/run-14/checkpoint-3000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-3000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-3500\n",
      "Configuration saved in ./training_output/run-14/checkpoint-3500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-3500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-4000\n",
      "Configuration saved in ./training_output/run-14/checkpoint-4000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-4000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-4500\n",
      "Configuration saved in ./training_output/run-14/checkpoint-4500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-4500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-4500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-4500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-4500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-4500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-14/checkpoint-5000\n",
      "Configuration saved in ./training_output/run-14/checkpoint-5000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-5000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-5000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-5000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-14/checkpoint-5000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-14/checkpoint-5000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "\u001b[32m[I 2021-07-22 21:37:44,440]\u001b[0m Trial 14 finished with value: 0.6286336357917458 and parameters: {'learning_rate': 0.000995778875486788, 'num_train_epochs': 19}. Best is trial 14 with value: 0.6286336357917458.\u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='269' max='5360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 269/5360 01:12 < 23:11, 3.66 it/s, Epoch 1/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.607956</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "\u001b[32m[I 2021-07-22 21:39:05,197]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 17\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4557' max='4556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4556/4556 22:00, Epoch 17/17]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.438847</td>\n",
       "      <td>0.533770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.466400</td>\n",
       "      <td>0.418050</td>\n",
       "      <td>0.564447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.466400</td>\n",
       "      <td>0.445227</td>\n",
       "      <td>0.528616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.483113</td>\n",
       "      <td>0.557710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.570023</td>\n",
       "      <td>0.558044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.313200</td>\n",
       "      <td>0.394897</td>\n",
       "      <td>0.615329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.313200</td>\n",
       "      <td>0.413560</td>\n",
       "      <td>0.602414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.275100</td>\n",
       "      <td>0.369561</td>\n",
       "      <td>0.618266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.275100</td>\n",
       "      <td>0.462748</td>\n",
       "      <td>0.611077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.617357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.242000</td>\n",
       "      <td>0.451664</td>\n",
       "      <td>0.601244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.582996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>0.584181</td>\n",
       "      <td>0.589040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.534735</td>\n",
       "      <td>0.599035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.556757</td>\n",
       "      <td>0.605713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>0.572421</td>\n",
       "      <td>0.608449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.598648</td>\n",
       "      <td>0.605767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-16/checkpoint-500\n",
      "Configuration saved in ./training_output/run-16/checkpoint-500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-16/checkpoint-1000\n",
      "Configuration saved in ./training_output/run-16/checkpoint-1000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-1000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-1000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-1000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-16/checkpoint-1500\n",
      "Configuration saved in ./training_output/run-16/checkpoint-1500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-1500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-1500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-1500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-16/checkpoint-2000\n",
      "Configuration saved in ./training_output/run-16/checkpoint-2000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-2000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-2000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-2000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-16/checkpoint-2500\n",
      "Configuration saved in ./training_output/run-16/checkpoint-2500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-2500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-2500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-2500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-16/checkpoint-3000\n",
      "Configuration saved in ./training_output/run-16/checkpoint-3000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-3000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-3000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-3000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-16/checkpoint-3500\n",
      "Configuration saved in ./training_output/run-16/checkpoint-3500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-3500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-3500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-3500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-16/checkpoint-4000\n",
      "Configuration saved in ./training_output/run-16/checkpoint-4000/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-4000/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-4000/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-4000/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/run-16/checkpoint-4500\n",
      "Configuration saved in ./training_output/run-16/checkpoint-4500/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-4500/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-4500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-4500/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/run-16/checkpoint-4500/cola/head_config.json\n",
      "Module weights saved in ./training_output/run-16/checkpoint-4500/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-07-22 22:01:13,833]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 18\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='269' max='4824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 269/4824 01:13 < 20:46, 3.66 it/s, Epoch 1/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.480544</td>\n",
       "      <td>0.482941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-07-22 22:02:34,865]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='269' max='4020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 269/4020 01:12 < 17:04, 3.66 it/s, Epoch 1/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.562345</td>\n",
       "      <td>0.188310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "\u001b[32m[I 2021-07-22 22:03:55,817]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "Trial:\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5360\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='269' max='5360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 269/5360 01:12 < 23:09, 3.66 it/s, Epoch 1/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.614481</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "\u001b[32m[I 2021-07-22 22:05:16,746]\u001b[0m Trial 19 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_trial = trainer.hyperparameter_search(\n",
    "    hp_space = hp_space,\n",
    "    direction = \"maximize\",\n",
    "    n_trials = 20,\n",
    "    #backend = \"optuna\",\n",
    "    #n_jobs = 4,\n",
    "    #n_samples = 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6TpP_EXxW9h",
    "outputId": "4853af97-cbfd-4807-ef59-0663c994673f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BestRun(run_id='14', objective=0.6286336357917458, hyperparameters={'learning_rate': 0.000995778875486788, 'num_train_epochs': 19})"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iHhoYuLIdX3"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsJyzkV--THN"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    \n",
    "   preds = np.argmax(p.predictions, axis=1)\n",
    "   acc = (preds == p.label_ids).mean()\n",
    "   mat = metrics.matthews_corrcoef(p.label_ids, preds)\n",
    "   f1 = metrics.f1_score(p.label_ids, preds)\n",
    "\n",
    "   return metric.compute(predictions=preds, references= p.label_ids)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=0.0001,\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    logging_strategy = 'epoch',\n",
    "    #eval_steps=500,\n",
    "    #logging_steps=500,\n",
    "    output_dir=\"./training_output\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    "    metric_for_best_model = 'eval_matthews_correlation',\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "\n",
    "create_trainer = functools.partial(Trainer, args=training_args, \n",
    "                                   train_dataset=dataset[\"train\"],\n",
    "                                   eval_dataset=dataset[\"validation\"],\n",
    "                                   compute_metrics=compute_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nGwjrr0diqSP",
    "outputId": "2561ea4a-8850-4097-e3a1-32ac484af92f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Reduction_factor =  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 43:22, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.589734</td>\n",
       "      <td>0.458993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.390500</td>\n",
       "      <td>0.548295</td>\n",
       "      <td>0.541655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.493057</td>\n",
       "      <td>0.577918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.279500</td>\n",
       "      <td>0.431293</td>\n",
       "      <td>0.631787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.519448</td>\n",
       "      <td>0.595815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.620128</td>\n",
       "      <td>0.603317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.164400</td>\n",
       "      <td>0.644509</td>\n",
       "      <td>0.586313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.145900</td>\n",
       "      <td>0.656671</td>\n",
       "      <td>0.593281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>0.667013</td>\n",
       "      <td>0.596174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.119800</td>\n",
       "      <td>0.645461</td>\n",
       "      <td>0.598573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>0.642316</td>\n",
       "      <td>0.606335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.088200</td>\n",
       "      <td>0.902064</td>\n",
       "      <td>0.591594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.855435</td>\n",
       "      <td>0.586313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.985960</td>\n",
       "      <td>0.593197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.871698</td>\n",
       "      <td>0.619024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>0.888516</td>\n",
       "      <td>0.586147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.821739</td>\n",
       "      <td>0.622224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.921951</td>\n",
       "      <td>0.629458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.947560</td>\n",
       "      <td>0.603774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.045892</td>\n",
       "      <td>0.610967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>1.245652</td>\n",
       "      <td>0.610681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>1.069842</td>\n",
       "      <td>0.618897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.033100</td>\n",
       "      <td>1.183508</td>\n",
       "      <td>0.613722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>1.187036</td>\n",
       "      <td>0.602180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>1.213568</td>\n",
       "      <td>0.625157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>1.355646</td>\n",
       "      <td>0.610874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.310184</td>\n",
       "      <td>0.614400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>1.277409</td>\n",
       "      <td>0.617855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>1.380915</td>\n",
       "      <td>0.611204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>1.368157</td>\n",
       "      <td>0.609160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-268/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-268/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-536/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-536/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-804/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-804/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1072/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1072/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1340/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1340/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1608/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1608/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1876/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1876/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2144/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2144/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2412/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2412/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2680/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2680/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2948/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2948/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3216/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3216/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3484/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3484/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3752/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3752/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4020/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4020/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4288/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4288/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4556/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4556/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4824/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4824/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5092/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5092/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5360/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5360/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5628/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5628/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5896/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5896/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6164/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6164/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6432/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6432/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6700/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6700/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6968/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6968/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7236/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7236/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7504/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7504/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7772/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7772/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-8040/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-8040/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-1072 (score: 0.6317871775012913).\n",
      "Loading module configuration from ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-1072 (score: 0.6317871775012913).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Reduction_factor =  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 40:35, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.548100</td>\n",
       "      <td>0.505836</td>\n",
       "      <td>0.443967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.431800</td>\n",
       "      <td>0.578230</td>\n",
       "      <td>0.425671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.525578</td>\n",
       "      <td>0.515318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.361900</td>\n",
       "      <td>0.408402</td>\n",
       "      <td>0.581789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.336900</td>\n",
       "      <td>0.487441</td>\n",
       "      <td>0.560441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.563808</td>\n",
       "      <td>0.557826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.458223</td>\n",
       "      <td>0.588199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.269200</td>\n",
       "      <td>0.548812</td>\n",
       "      <td>0.581056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.247100</td>\n",
       "      <td>0.456079</td>\n",
       "      <td>0.600879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.524746</td>\n",
       "      <td>0.578349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.422749</td>\n",
       "      <td>0.574420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.215100</td>\n",
       "      <td>0.529941</td>\n",
       "      <td>0.598107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.555976</td>\n",
       "      <td>0.595616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.616747</td>\n",
       "      <td>0.587287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.597353</td>\n",
       "      <td>0.570138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.176700</td>\n",
       "      <td>0.538377</td>\n",
       "      <td>0.580647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.164400</td>\n",
       "      <td>0.553052</td>\n",
       "      <td>0.588697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.161000</td>\n",
       "      <td>0.570663</td>\n",
       "      <td>0.588414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.575218</td>\n",
       "      <td>0.593382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.694456</td>\n",
       "      <td>0.580530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.137900</td>\n",
       "      <td>0.665321</td>\n",
       "      <td>0.593084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.662818</td>\n",
       "      <td>0.577859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.685921</td>\n",
       "      <td>0.570636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.794767</td>\n",
       "      <td>0.573254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.117400</td>\n",
       "      <td>0.753532</td>\n",
       "      <td>0.587976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.112800</td>\n",
       "      <td>0.773665</td>\n",
       "      <td>0.582897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.768468</td>\n",
       "      <td>0.580372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>0.812654</td>\n",
       "      <td>0.577794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.785227</td>\n",
       "      <td>0.572701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.788093</td>\n",
       "      <td>0.570174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-268/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-268/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-536/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-536/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-804/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-804/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1072/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1072/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1340/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1340/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1608/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1608/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1876/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1876/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2144/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2144/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2412/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2412/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2680/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2680/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2948/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2948/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3216/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3216/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3484/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3484/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3752/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3752/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4020/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4020/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4288/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4288/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4556/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4556/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4824/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4824/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5092/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5092/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5360/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5360/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5628/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5628/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5896/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5896/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6164/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6164/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6432/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6432/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6700/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6700/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6968/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6968/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7236/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7236/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7504/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7504/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7772/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7772/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-8040/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-8040/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-2412 (score: 0.6008788381144764).\n",
      "Loading module configuration from ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-2412 (score: 0.6008788381144764).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Reduction_factor =  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 40:19, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.592600</td>\n",
       "      <td>0.531868</td>\n",
       "      <td>0.325124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>0.476217</td>\n",
       "      <td>0.472135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.425100</td>\n",
       "      <td>0.504185</td>\n",
       "      <td>0.485946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.402500</td>\n",
       "      <td>0.456604</td>\n",
       "      <td>0.510041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.379800</td>\n",
       "      <td>0.479332</td>\n",
       "      <td>0.531416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.484490</td>\n",
       "      <td>0.531838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.356600</td>\n",
       "      <td>0.413006</td>\n",
       "      <td>0.573511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>0.471047</td>\n",
       "      <td>0.578205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.444402</td>\n",
       "      <td>0.593133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.323400</td>\n",
       "      <td>0.425182</td>\n",
       "      <td>0.593055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.417068</td>\n",
       "      <td>0.591244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.308900</td>\n",
       "      <td>0.400914</td>\n",
       "      <td>0.597159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.294200</td>\n",
       "      <td>0.453739</td>\n",
       "      <td>0.598573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.469739</td>\n",
       "      <td>0.601232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>0.454756</td>\n",
       "      <td>0.593055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.283200</td>\n",
       "      <td>0.472411</td>\n",
       "      <td>0.593405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.494110</td>\n",
       "      <td>0.616372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.458371</td>\n",
       "      <td>0.593045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.271300</td>\n",
       "      <td>0.447628</td>\n",
       "      <td>0.608191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.493492</td>\n",
       "      <td>0.611091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.255200</td>\n",
       "      <td>0.469605</td>\n",
       "      <td>0.603246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.472630</td>\n",
       "      <td>0.600638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.484842</td>\n",
       "      <td>0.598195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.471178</td>\n",
       "      <td>0.608284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.243000</td>\n",
       "      <td>0.480940</td>\n",
       "      <td>0.610742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.237100</td>\n",
       "      <td>0.495386</td>\n",
       "      <td>0.615736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>0.494448</td>\n",
       "      <td>0.610683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.502060</td>\n",
       "      <td>0.608232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.236700</td>\n",
       "      <td>0.498489</td>\n",
       "      <td>0.605682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.497574</td>\n",
       "      <td>0.603147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-268/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-268/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-536/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-536/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-804/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-804/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1072/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1072/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1340/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1340/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1608/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1608/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1876/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1876/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2144/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2144/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2412/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2412/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2680/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2680/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2948/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2948/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3216/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3216/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3484/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3484/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3752/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3752/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4020/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4020/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4288/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4288/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4556/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4556/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4824/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4824/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5092/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5092/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5360/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5360/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5628/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5628/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5896/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5896/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6164/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6164/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6432/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6432/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6700/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6700/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6968/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6968/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7236/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7236/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7504/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7504/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7772/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7772/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-8040/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-8040/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-4556 (score: 0.616371958291421).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-4556 (score: 0.616371958291421).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "Reduction_factor =  256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 40:17, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.567503</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.470330</td>\n",
       "      <td>0.488446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.497147</td>\n",
       "      <td>0.469217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>0.467598</td>\n",
       "      <td>0.493854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.409800</td>\n",
       "      <td>0.464449</td>\n",
       "      <td>0.520756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.405700</td>\n",
       "      <td>0.473181</td>\n",
       "      <td>0.509989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.390500</td>\n",
       "      <td>0.435582</td>\n",
       "      <td>0.555443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>0.460472</td>\n",
       "      <td>0.539126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.375400</td>\n",
       "      <td>0.451865</td>\n",
       "      <td>0.547487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.439051</td>\n",
       "      <td>0.555809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.433179</td>\n",
       "      <td>0.566158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.363600</td>\n",
       "      <td>0.406592</td>\n",
       "      <td>0.584357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.432165</td>\n",
       "      <td>0.576887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.422612</td>\n",
       "      <td>0.573883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.350300</td>\n",
       "      <td>0.451125</td>\n",
       "      <td>0.557611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>0.471087</td>\n",
       "      <td>0.559874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.454073</td>\n",
       "      <td>0.562781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>0.441802</td>\n",
       "      <td>0.575436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.430009</td>\n",
       "      <td>0.566158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.449003</td>\n",
       "      <td>0.575641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.335800</td>\n",
       "      <td>0.436729</td>\n",
       "      <td>0.568945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.435474</td>\n",
       "      <td>0.568736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>0.449071</td>\n",
       "      <td>0.568367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.325100</td>\n",
       "      <td>0.435181</td>\n",
       "      <td>0.576451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.441388</td>\n",
       "      <td>0.568736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.443828</td>\n",
       "      <td>0.568736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.440458</td>\n",
       "      <td>0.571311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.452154</td>\n",
       "      <td>0.568207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.447753</td>\n",
       "      <td>0.570780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.315600</td>\n",
       "      <td>0.444978</td>\n",
       "      <td>0.573350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-268/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-268/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-536/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-536/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-804/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-804/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1072/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1072/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1340/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1340/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1608/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1608/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-1876/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-1876/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2144/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2144/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2412/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2412/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2680/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2680/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-2948/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-2948/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3216/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3216/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3484/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3484/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-3752/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-3752/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4020/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4020/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4288/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4288/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4556/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4556/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-4824/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-4824/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5092/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5092/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5360/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5360/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5628/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5628/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-5896/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-5896/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6164/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6164/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6432/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6432/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6700/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6700/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-6968/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-6968/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7236/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7236/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7504/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7504/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-7772/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-7772/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "tokenizer config file saved in ./training_output/checkpoint-8040/tokenizer_config.json\n",
      "Special tokens file saved in ./training_output/checkpoint-8040/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-3216 (score: 0.5843571592017298).\n",
      "Loading module configuration from ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-3216 (score: 0.5843571592017298).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for red in [2, 16, 64, 256]:\n",
    "  print('\\n\\n************************************************************')\n",
    "  print('Reduction_factor = ',red)\n",
    "  config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "  model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "  adapter_config = transformers.PfeifferConfig(reduction_factor=red)\n",
    "  model.add_adapter(\"cola\", config=adapter_config)\n",
    "  model.add_classification_head(\"cola\", num_labels=2)\n",
    "  model.train_adapter(\"cola\")\n",
    "\n",
    "  trainer = Trainer(\n",
    "      model=model,\n",
    "      args=training_args,\n",
    "      #tokenizer=tokenizer,\n",
    "      #model_init = model_init,\n",
    "      train_dataset=dataset[\"train\"],\n",
    "      eval_dataset=dataset[\"validation\"],\n",
    "      compute_metrics=compute_metrics,\n",
    "  )\n",
    "\n",
    "  trainer.train()\n",
    "  display(trainer.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdV5PiBNe7zL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PBgOb9L94hJ"
   },
   "source": [
    "## Ablation\n",
    "\n",
    "**Ablation 1: Lower layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "UcZMwiJ_KDdP",
    "outputId": "fe2cbcb4-b254-4fc4-8552-a0e8de75e3b4",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 41:11, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.540500</td>\n",
       "      <td>0.610001</td>\n",
       "      <td>0.444365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.428600</td>\n",
       "      <td>0.532620</td>\n",
       "      <td>0.506820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.522263</td>\n",
       "      <td>0.555285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.319800</td>\n",
       "      <td>0.424646</td>\n",
       "      <td>0.600984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.276400</td>\n",
       "      <td>0.477334</td>\n",
       "      <td>0.572799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.560733</td>\n",
       "      <td>0.562455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.542599</td>\n",
       "      <td>0.590659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.599135</td>\n",
       "      <td>0.583169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>0.567605</td>\n",
       "      <td>0.609780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>0.776762</td>\n",
       "      <td>0.568142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.754469</td>\n",
       "      <td>0.625306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>0.784684</td>\n",
       "      <td>0.588414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.620789</td>\n",
       "      <td>0.614834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.715053</td>\n",
       "      <td>0.575916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.704198</td>\n",
       "      <td>0.593382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>0.776764</td>\n",
       "      <td>0.607737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.864572</td>\n",
       "      <td>0.600122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.794372</td>\n",
       "      <td>0.614977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.806813</td>\n",
       "      <td>0.589046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.859022</td>\n",
       "      <td>0.608449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>1.072226</td>\n",
       "      <td>0.600671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>1.024413</td>\n",
       "      <td>0.621408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>1.002876</td>\n",
       "      <td>0.616546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>1.086231</td>\n",
       "      <td>0.605723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>1.083165</td>\n",
       "      <td>0.626270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>1.185119</td>\n",
       "      <td>0.608191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.201167</td>\n",
       "      <td>0.620910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>1.200046</td>\n",
       "      <td>0.614029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>1.229531</td>\n",
       "      <td>0.603931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>1.223285</td>\n",
       "      <td>0.609160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-6700 (score: 0.6262696480582318).\n",
      "Loading module configuration from ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-6700 (score: 0.6262696480582318).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 1.0831646919250488,\n",
       " 'eval_matthews_correlation': 0.6262696480582318,\n",
       " 'eval_runtime': 4.8539,\n",
       " 'eval_samples_per_second': 214.879,\n",
       " 'eval_steps_per_second': 6.799}"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "adapter_config = transformers.PfeifferConfig(reduction_factor={\"0\":256, \"1\":256, \"2\":256, \"default\": 2})\n",
    "model.add_adapter(\"cola\", config=adapter_config)\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "model.train_adapter(\"cola\")\n",
    "\n",
    "trainer = create_trainer(model)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGYF9aPJJjg5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgKoy-vIJjrF"
   },
   "source": [
    "**Ablation 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_X8nr2pw-Crr",
    "outputId": "baa4038f-0779-4f52-e79e-ef421e40fb4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 41:17, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.623500</td>\n",
       "      <td>0.452454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0.576339</td>\n",
       "      <td>0.499515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.362300</td>\n",
       "      <td>0.506114</td>\n",
       "      <td>0.531171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.308900</td>\n",
       "      <td>0.432602</td>\n",
       "      <td>0.585349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.515187</td>\n",
       "      <td>0.558246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.581513</td>\n",
       "      <td>0.557240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>0.590177</td>\n",
       "      <td>0.554658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.167700</td>\n",
       "      <td>0.627619</td>\n",
       "      <td>0.568736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.141100</td>\n",
       "      <td>0.697744</td>\n",
       "      <td>0.577811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.704279</td>\n",
       "      <td>0.588298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.612348</td>\n",
       "      <td>0.589455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.818146</td>\n",
       "      <td>0.562582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.636342</td>\n",
       "      <td>0.603634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>1.010045</td>\n",
       "      <td>0.552207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.653967</td>\n",
       "      <td>0.615883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.817632</td>\n",
       "      <td>0.616726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.937429</td>\n",
       "      <td>0.588863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.951108</td>\n",
       "      <td>0.615883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.927099</td>\n",
       "      <td>0.594555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>1.100387</td>\n",
       "      <td>0.562403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>1.035074</td>\n",
       "      <td>0.601758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>1.051664</td>\n",
       "      <td>0.611115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>1.126982</td>\n",
       "      <td>0.624079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>1.200730</td>\n",
       "      <td>0.603405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>1.139954</td>\n",
       "      <td>0.619650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>1.229001</td>\n",
       "      <td>0.615994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>1.308244</td>\n",
       "      <td>0.608684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>1.276248</td>\n",
       "      <td>0.618503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>1.278839</td>\n",
       "      <td>0.616546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>1.308233</td>\n",
       "      <td>0.613722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-6164 (score: 0.6240786802650855).\n",
      "Loading module configuration from ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-6164 (score: 0.6240786802650855).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 1.1269817352294922,\n",
       " 'eval_matthews_correlation': 0.6240786802650855,\n",
       " 'eval_runtime': 4.8677,\n",
       " 'eval_samples_per_second': 214.271,\n",
       " 'eval_steps_per_second': 6.779}"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "adapter_config = transformers.PfeifferConfig(reduction_factor={\"9\":256, \"10\":256, \"11\":256, \"default\": 2})\n",
    "model.add_adapter(\"cola\", config=adapter_config)\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "model.train_adapter(\"cola\")\n",
    "\n",
    "trainer = create_trainer(model)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAYQyTHZ-CsR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WDa92VXYrDx"
   },
   "source": [
    "**Ablation 3:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sLjBUtld-CtG",
    "outputId": "0cf2de49-84f8-422b-c50e-230c51412168"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 41:18, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.538600</td>\n",
       "      <td>0.658154</td>\n",
       "      <td>0.395854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.571452</td>\n",
       "      <td>0.500296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.355900</td>\n",
       "      <td>0.532409</td>\n",
       "      <td>0.547514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.450677</td>\n",
       "      <td>0.585866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.497861</td>\n",
       "      <td>0.578205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.605704</td>\n",
       "      <td>0.582240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.487135</td>\n",
       "      <td>0.585573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.714060</td>\n",
       "      <td>0.565754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.814567</td>\n",
       "      <td>0.562623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.622671</td>\n",
       "      <td>0.585536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.546650</td>\n",
       "      <td>0.606459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.112000</td>\n",
       "      <td>0.918170</td>\n",
       "      <td>0.568512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>0.819747</td>\n",
       "      <td>0.570179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.850064</td>\n",
       "      <td>0.560090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.754608</td>\n",
       "      <td>0.599424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>0.937810</td>\n",
       "      <td>0.562407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>1.046016</td>\n",
       "      <td>0.591017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.933702</td>\n",
       "      <td>0.588199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.957993</td>\n",
       "      <td>0.603317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.052300</td>\n",
       "      <td>1.021534</td>\n",
       "      <td>0.580453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>1.106469</td>\n",
       "      <td>0.577906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.083042</td>\n",
       "      <td>0.588298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>1.168589</td>\n",
       "      <td>0.588863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>1.244102</td>\n",
       "      <td>0.570322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>1.201612</td>\n",
       "      <td>0.598453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>1.223012</td>\n",
       "      <td>0.595575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>1.259640</td>\n",
       "      <td>0.585436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>1.356297</td>\n",
       "      <td>0.593045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>1.380163</td>\n",
       "      <td>0.580349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>1.351974</td>\n",
       "      <td>0.588009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-2948 (score: 0.6064593797294897).\n",
      "Loading module configuration from ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-2948 (score: 0.6064593797294897).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.5466495752334595,\n",
       " 'eval_matthews_correlation': 0.6064593797294897,\n",
       " 'eval_runtime': 4.8619,\n",
       " 'eval_samples_per_second': 214.527,\n",
       " 'eval_steps_per_second': 6.788}"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "adapter_config = transformers.PfeifferConfig(reduction_factor={\"8\":256, \"7\":256, \"6\":256, \"default\": 2})\n",
    "model.add_adapter(\"cola\", config=adapter_config)\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "model.train_adapter(\"cola\")\n",
    "\n",
    "trainer = create_trainer(model)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nJL0o8dKj_mx",
    "outputId": "47198e29-b03d-4bb4-bdb3-31fd9db891da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding adapter 'cola'.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 41:17, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.536400</td>\n",
       "      <td>0.606333</td>\n",
       "      <td>0.412377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>0.611808</td>\n",
       "      <td>0.490589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354100</td>\n",
       "      <td>0.549541</td>\n",
       "      <td>0.514231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.305000</td>\n",
       "      <td>0.461543</td>\n",
       "      <td>0.565160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258200</td>\n",
       "      <td>0.532151</td>\n",
       "      <td>0.568142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.582078</td>\n",
       "      <td>0.567677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.595365</td>\n",
       "      <td>0.575972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.611440</td>\n",
       "      <td>0.611091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.652654</td>\n",
       "      <td>0.608229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.664657</td>\n",
       "      <td>0.585706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.742625</td>\n",
       "      <td>0.615994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>1.010890</td>\n",
       "      <td>0.548681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.694616</td>\n",
       "      <td>0.595610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.820254</td>\n",
       "      <td>0.568512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>0.619530</td>\n",
       "      <td>0.611348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.782464</td>\n",
       "      <td>0.623177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.868603</td>\n",
       "      <td>0.608191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.897630</td>\n",
       "      <td>0.625760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>1.031180</td>\n",
       "      <td>0.599563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.961624</td>\n",
       "      <td>0.610872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>1.108382</td>\n",
       "      <td>0.593405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>1.061551</td>\n",
       "      <td>0.608985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.043700</td>\n",
       "      <td>1.030703</td>\n",
       "      <td>0.609351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>1.135579</td>\n",
       "      <td>0.590521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.957382</td>\n",
       "      <td>0.623765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>1.105765</td>\n",
       "      <td>0.625827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>1.210856</td>\n",
       "      <td>0.620694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>1.206432</td>\n",
       "      <td>0.623187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>1.222567</td>\n",
       "      <td>0.620692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>1.235443</td>\n",
       "      <td>0.615693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-6968 (score: 0.6258269726983982).\n",
      "Loading module configuration from ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-6968 (score: 0.6258269726983982).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 1.1057647466659546,\n",
       " 'eval_matthews_correlation': 0.6258269726983982,\n",
       " 'eval_runtime': 4.8842,\n",
       " 'eval_samples_per_second': 213.546,\n",
       " 'eval_steps_per_second': 6.756}"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "adapter_config = transformers.PfeifferConfig(reduction_factor={\"3\":256, \"4\":256, \"5\":256, \"default\": 2})\n",
    "model.add_adapter(\"cola\", config=adapter_config)\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "model.train_adapter(\"cola\")\n",
    "\n",
    "trainer = create_trainer(model)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hXv2rJfrOnx-"
   },
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIAQe8ElOqoI",
    "outputId": "9fa853bd-cdbc-4588-efbd-f5ad2f8b7305"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModelWithHeads(\n",
       "  (roberta): RobertaModel(\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (cola): ClassificationHead(\n",
       "      (0): Dropout(p=0.1, inplace=False)\n",
       "      (1): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (2): Activation_Function_Class()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=768, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "#adapter_config = transformers.PfeifferConfig(reduction_factor=16)\n",
    "#model.add_adapter(\"cola\", config=adapter_config)\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "#model.train_adapter(\"cola\")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOuiH-rzPsoU",
    "outputId": "ef6c4094-26b4-4d33-8ea3-126ccdf216da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads.cola.1.weight\n",
      "heads.cola.1.bias\n",
      "heads.cola.4.weight\n",
      "heads.cola.4.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "  #print(name)\n",
    "  if 'cola' not in name:\n",
    "    param.requires_grad = False\n",
    "  else:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3TIs4nNwPkkd",
    "outputId": "7c143fe5-3726-482a-f562-22c1b86d6535"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 22:08, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>0.611670</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.600700</td>\n",
       "      <td>0.602055</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.593400</td>\n",
       "      <td>0.595618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.587100</td>\n",
       "      <td>0.588946</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.582600</td>\n",
       "      <td>0.582544</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.576500</td>\n",
       "      <td>0.579365</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.571500</td>\n",
       "      <td>0.582285</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.574400</td>\n",
       "      <td>0.570849</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.572860</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.568200</td>\n",
       "      <td>0.563024</td>\n",
       "      <td>0.073807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.567400</td>\n",
       "      <td>0.574680</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.563100</td>\n",
       "      <td>0.552687</td>\n",
       "      <td>0.216249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.560500</td>\n",
       "      <td>0.563525</td>\n",
       "      <td>0.073807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.556400</td>\n",
       "      <td>0.550871</td>\n",
       "      <td>0.182360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.555800</td>\n",
       "      <td>0.558437</td>\n",
       "      <td>0.125930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>0.582270</td>\n",
       "      <td>0.080368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.555400</td>\n",
       "      <td>0.550069</td>\n",
       "      <td>0.182360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>0.550288</td>\n",
       "      <td>0.182360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.549700</td>\n",
       "      <td>0.547192</td>\n",
       "      <td>0.217796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.550700</td>\n",
       "      <td>0.567284</td>\n",
       "      <td>0.097582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>0.544878</td>\n",
       "      <td>0.215188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>0.548918</td>\n",
       "      <td>0.196435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.548300</td>\n",
       "      <td>0.549981</td>\n",
       "      <td>0.199722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.551200</td>\n",
       "      <td>0.541526</td>\n",
       "      <td>0.226083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.556300</td>\n",
       "      <td>0.542631</td>\n",
       "      <td>0.227936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.545200</td>\n",
       "      <td>0.549256</td>\n",
       "      <td>0.190767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.544200</td>\n",
       "      <td>0.545943</td>\n",
       "      <td>0.212634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.541700</td>\n",
       "      <td>0.546404</td>\n",
       "      <td>0.212634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.545506</td>\n",
       "      <td>0.217796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.545820</td>\n",
       "      <td>0.217796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/config.json\n",
      "Model weights saved in ./training_output/checkpoint-268/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/config.json\n",
      "Model weights saved in ./training_output/checkpoint-536/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/config.json\n",
      "Model weights saved in ./training_output/checkpoint-804/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/config.json\n",
      "Model weights saved in ./training_output/checkpoint-1072/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/config.json\n",
      "Model weights saved in ./training_output/checkpoint-1340/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/config.json\n",
      "Model weights saved in ./training_output/checkpoint-1608/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/config.json\n",
      "Model weights saved in ./training_output/checkpoint-1876/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/config.json\n",
      "Model weights saved in ./training_output/checkpoint-2144/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/config.json\n",
      "Model weights saved in ./training_output/checkpoint-2412/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/config.json\n",
      "Model weights saved in ./training_output/checkpoint-2680/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/config.json\n",
      "Model weights saved in ./training_output/checkpoint-2948/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/config.json\n",
      "Model weights saved in ./training_output/checkpoint-3216/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/config.json\n",
      "Model weights saved in ./training_output/checkpoint-3484/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/config.json\n",
      "Model weights saved in ./training_output/checkpoint-3752/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/config.json\n",
      "Model weights saved in ./training_output/checkpoint-4020/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/config.json\n",
      "Model weights saved in ./training_output/checkpoint-4288/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/config.json\n",
      "Model weights saved in ./training_output/checkpoint-4556/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/config.json\n",
      "Model weights saved in ./training_output/checkpoint-4824/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/config.json\n",
      "Model weights saved in ./training_output/checkpoint-5092/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/config.json\n",
      "Model weights saved in ./training_output/checkpoint-5360/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/config.json\n",
      "Model weights saved in ./training_output/checkpoint-5628/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/config.json\n",
      "Model weights saved in ./training_output/checkpoint-5896/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/config.json\n",
      "Model weights saved in ./training_output/checkpoint-6164/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/config.json\n",
      "Model weights saved in ./training_output/checkpoint-6432/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/config.json\n",
      "Model weights saved in ./training_output/checkpoint-6700/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/config.json\n",
      "Model weights saved in ./training_output/checkpoint-6968/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/config.json\n",
      "Model weights saved in ./training_output/checkpoint-7236/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/config.json\n",
      "Model weights saved in ./training_output/checkpoint-7504/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/config.json\n",
      "Model weights saved in ./training_output/checkpoint-7772/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/config.json\n",
      "Model weights saved in ./training_output/checkpoint-8040/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./training_output/checkpoint-6700 (score: 0.2279360616503532).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.542631208896637,\n",
       " 'eval_matthews_correlation': 0.2279360616503532,\n",
       " 'eval_runtime': 4.5045,\n",
       " 'eval_samples_per_second': 231.548,\n",
       " 'eval_steps_per_second': 7.326}"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = create_trainer(model)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwmHGtlw90cI"
   },
   "source": [
    "## Adapter Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282,
     "referenced_widgets": [
      "9976580653bf48d8a5c556e1d84efa05",
      "9574a1cab2ab42c788d51f1f40d1b57b",
      "4603464810b64c70bcbb283bc53e443a",
      "a9a4de7332ca41d39b32dd9254661b01",
      "92dcd66282fa453aad12ed03f1651738",
      "78076f7c11ba44228224d55f7e06e539",
      "dc71772258de4fb592bce57764f707c4",
      "f278e58cab344659828e21cb7d5478a6",
      "a4fe36276f554f6e82ed05271fd02736",
      "534615ae35a54cb7b32348c0d4c3b428",
      "8a49edc995184c5abc8bd65aa484fb89",
      "8c8a5493381041b2a52863d2ee5b0051",
      "56a71f4da04d41c081066809ffb7c309",
      "524ecaf8f53b483395b5645d1d74fc72",
      "bf622f4a417b4c6599dd165681f94782",
      "c2331cfc31684ad8a2eb4020227f8fd7",
      "96d0a76b3b7f4f7d97979a182fc55945",
      "833b18dda07a4cbeb37e8a59bafc4553",
      "c62be8e2ea2c4313ba0fe258109cc914",
      "f26caf9ff5354b6d857095e399cb20b7",
      "91bc6994bb00403e95ac91c1a40b9879",
      "f54e5fb9d8a24a81af674cf1ce9a654b",
      "36735c3e7c40461589cbe271898c04e6",
      "9aad2037900448adbf8dc1103c71ed1c",
      "ea387d97f4db4c0596afc15596259049",
      "92475cd2561a43ed980178243eb70874",
      "efc8b5da402e443ebe17640803915d1d",
      "e07be9e6d4b24838bb945efe16aac040",
      "a960ec3f059b4bdebce9dbc60feae07b",
      "71b2aae93c944b85af685cd0289277c3",
      "6a247d4c32544978b13871a2005581b8",
      "7eb8c97f48b7435884ecaac656cc0039",
      "0fa462a612db4f458e7c6b64e8df4b5a",
      "2268cd0c6fff410a99513d0ec0bffe09",
      "788eaced3a934c79819b095391fad060",
      "8f10aefb539a43a2a1b2ae3c2f037d36",
      "8a91c2b9b68f4837805432d81c944831",
      "2fb41cc4925b49faae22190007d6a21b",
      "e07fd02b48484c3d83762a00723497f2",
      "3e1d0a98974048c3a5d3034e4a0eb3da",
      "b63defab5ac34420914aaa78d2b98ce0",
      "11a2ab6d5d554369b21bf7654ceb8fd7",
      "7e4c1c1f1753465194b1aec5e811848c",
      "3232dd6917514640b583c44857b2ff23",
      "d0b16b61dca047fb9fb8c3f6626f9c62",
      "47194bc8853b4ca4adf96f710a87e6b1",
      "69e623122e234e2882eb659c00df00d3",
      "0696c435d3a34e90a528611216872733",
      "b21ea221be2a4b89803e7bfd4b64aea4",
      "d82e0b341191488a8704204373f9c210",
      "d97b832a3f0f41bb831d5a025b7dccca",
      "b6aabffd6d6d42f1b74e876c298b8ad1",
      "761ea39c51d348e4920ed3909100bb79",
      "6fa88842b67e478f9c39355bebe32c30",
      "86d3fabdfb7b450db687d71da95ef9fd"
     ]
    },
    "id": "yG-hCNkL90rN",
    "outputId": "c648b987-a5b4-4a13-db8e-20f52aab44e8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9976580653bf48d8a5c556e1d84efa05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8a5493381041b2a52863d2ee5b0051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/540 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36735c3e7c40461589cbe271898c04e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2268cd0c6fff410a99513d0ec0bffe09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.33M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b16b61dca047fb9fb8c3f6626f9c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.53M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers.adapters.composition import Fuse\n",
    "\n",
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "adapter_config = transformers.PfeifferConfig()\n",
    "model.load_adapter(\"nli/multinli@ukp\", load_as=\"multinli\", with_head=False)\n",
    "model.load_adapter(\"sts/qqp@ukp\", with_head=False)\n",
    "model.load_adapter(\"nli/qnli@ukp\", with_head=False)\n",
    "model.add_adapter_fusion(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
    "model.set_active_adapters(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
    "#model.add_adapter(\"cola\", config=adapter_config)\n",
    "\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"multinli\", \"qqp\", \"qnli\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "#model.train_adapter(\"cola\")\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1_1k5i2F_UEj",
    "outputId": "4204174b-47b0-49ee-d6bc-0263bcea6673"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 1:16:51, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.511800</td>\n",
       "      <td>0.689740</td>\n",
       "      <td>0.358391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.450700</td>\n",
       "      <td>0.483386</td>\n",
       "      <td>0.502412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.431800</td>\n",
       "      <td>0.515783</td>\n",
       "      <td>0.472382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.425558</td>\n",
       "      <td>0.528505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.409100</td>\n",
       "      <td>0.418846</td>\n",
       "      <td>0.547644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.462777</td>\n",
       "      <td>0.507428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.405700</td>\n",
       "      <td>0.414194</td>\n",
       "      <td>0.554397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.443834</td>\n",
       "      <td>0.531198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.402600</td>\n",
       "      <td>0.398549</td>\n",
       "      <td>0.571213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>0.446336</td>\n",
       "      <td>0.494827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.419499</td>\n",
       "      <td>0.556015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.495278</td>\n",
       "      <td>0.517948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.425764</td>\n",
       "      <td>0.552296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.521529</td>\n",
       "      <td>0.477432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.407967</td>\n",
       "      <td>0.549769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.360600</td>\n",
       "      <td>0.546308</td>\n",
       "      <td>0.484222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.408418</td>\n",
       "      <td>0.600243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.353200</td>\n",
       "      <td>0.465647</td>\n",
       "      <td>0.552318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.337300</td>\n",
       "      <td>0.489640</td>\n",
       "      <td>0.526263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>0.526099</td>\n",
       "      <td>0.503817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.583012</td>\n",
       "      <td>0.498116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.333800</td>\n",
       "      <td>0.439163</td>\n",
       "      <td>0.570941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.319100</td>\n",
       "      <td>0.472355</td>\n",
       "      <td>0.564996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.446885</td>\n",
       "      <td>0.560799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.318900</td>\n",
       "      <td>0.470070</td>\n",
       "      <td>0.572872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.476692</td>\n",
       "      <td>0.578821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.304200</td>\n",
       "      <td>0.504959</td>\n",
       "      <td>0.559852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>0.500300</td>\n",
       "      <td>0.570305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.475213</td>\n",
       "      <td>0.576661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.292600</td>\n",
       "      <td>0.500342</td>\n",
       "      <td>0.565360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-4556 (score: 0.6002430722234355).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/multinli/adapter_config.json\n",
      "Overwriting existing adapter 'multinli'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/multinli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/multinli'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/qqp/adapter_config.json\n",
      "Overwriting existing adapter 'qqp'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/qqp/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/qqp'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/qnli/adapter_config.json\n",
      "Overwriting existing adapter 'qnli'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/qnli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/qnli'\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-4556 (score: 0.6002430722234355).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/multinli,qqp,qnli/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'multinli,qqp,qnli'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-4556/multinli,qqp,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.4254721701145172,\n",
       " 'eval_matthews_correlation': 0.5992421641912468,\n",
       " 'eval_runtime': 7.6531,\n",
       " 'eval_samples_per_second': 136.285,\n",
       " 'eval_steps_per_second': 4.312}"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STzkp2YUCxEN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qV6b4u_qCuy3"
   },
   "source": [
    "**Add CoLA to Fusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7aSgjWylCuRZ",
    "outputId": "cc56ce4e-eef9-4038-dedc-cd444f36d5fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 38:55, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.557400</td>\n",
       "      <td>0.490924</td>\n",
       "      <td>0.477905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.594486</td>\n",
       "      <td>0.418455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.399200</td>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.515291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.361900</td>\n",
       "      <td>0.413942</td>\n",
       "      <td>0.575641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.335600</td>\n",
       "      <td>0.478634</td>\n",
       "      <td>0.542309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.318100</td>\n",
       "      <td>0.530317</td>\n",
       "      <td>0.544411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.291700</td>\n",
       "      <td>0.443412</td>\n",
       "      <td>0.578479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.271200</td>\n",
       "      <td>0.548328</td>\n",
       "      <td>0.563013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.499306</td>\n",
       "      <td>0.585536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.242200</td>\n",
       "      <td>0.497786</td>\n",
       "      <td>0.573254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.423547</td>\n",
       "      <td>0.614625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.221100</td>\n",
       "      <td>0.519444</td>\n",
       "      <td>0.595732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>0.532906</td>\n",
       "      <td>0.615759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.584398</td>\n",
       "      <td>0.588651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.180200</td>\n",
       "      <td>0.561908</td>\n",
       "      <td>0.615790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.485553</td>\n",
       "      <td>0.614834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.502702</td>\n",
       "      <td>0.620910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.590805</td>\n",
       "      <td>0.603159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.534202</td>\n",
       "      <td>0.604292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.140400</td>\n",
       "      <td>0.646930</td>\n",
       "      <td>0.590523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>0.629017</td>\n",
       "      <td>0.608173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.123400</td>\n",
       "      <td>0.638367</td>\n",
       "      <td>0.595919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.707666</td>\n",
       "      <td>0.600722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.120600</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.598133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.686185</td>\n",
       "      <td>0.610874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>0.727408</td>\n",
       "      <td>0.608358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.712848</td>\n",
       "      <td>0.603317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.730971</td>\n",
       "      <td>0.603159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.755136</td>\n",
       "      <td>0.598195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.101900</td>\n",
       "      <td>0.762127</td>\n",
       "      <td>0.603159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-4556 (score: 0.6209103735772308).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-4556 (score: 0.6209103735772308).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.5027017593383789,\n",
       " 'eval_matthews_correlation': 0.6209103735772308,\n",
       " 'eval_runtime': 4.6536,\n",
       " 'eval_samples_per_second': 224.129,\n",
       " 'eval_steps_per_second': 7.091}"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "adapter_config = transformers.PfeifferConfig(reduction_factor=16)\n",
    "model.add_adapter(\"cola\", config=adapter_config)\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "model.train_adapter(\"cola\")\n",
    "\n",
    "trainer = create_trainer(model)\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTc9jic5CvXP",
    "outputId": "542fa06a-9f56-48b7-8737-4ec916465292"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./cola_roberta/adapter_config.json\n",
      "Module weights saved in ./cola_roberta/pytorch_adapter.bin\n",
      "Configuration saved in ./cola_roberta/head_config.json\n",
      "Module weights saved in ./cola_roberta/pytorch_model_head.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_adapter(\"./cola_roberta\", \"cola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zA9BAlVz3fML"
   },
   "source": [
    "**Fusion test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bf1LjPmk3ldd",
    "outputId": "e73b43fb-1e28-46ff-f0ea-a6ab25fc75b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading module configuration from ./cola_roberta/adapter_config.json\n",
      "Adding adapter 'cola'.\n",
      "Loading module weights from ./cola_roberta/pytorch_adapter.bin\n",
      "Could not identify 'Fuse[cola]' as a valid prediction head.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "from transformers.adapters.composition import Fuse\n",
    "\n",
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.load_adapter(\"./cola_roberta\", load_as=\"cola\", with_head=False)\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"cola\"))\n",
    "model.set_active_adapters(Fuse(\"cola\"))\n",
    "\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"cola\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uk6WdHax4Hk4",
    "outputId": "45ec49e3-9ad1-4ad3-ab7f-1b1aa28e9dc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 58:31, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.228200</td>\n",
       "      <td>0.612490</td>\n",
       "      <td>0.563188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.646221</td>\n",
       "      <td>0.571799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.189200</td>\n",
       "      <td>0.762658</td>\n",
       "      <td>0.561876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.644808</td>\n",
       "      <td>0.600954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.647215</td>\n",
       "      <td>0.585962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.611082</td>\n",
       "      <td>0.600954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.591960</td>\n",
       "      <td>0.585442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.177300</td>\n",
       "      <td>0.629348</td>\n",
       "      <td>0.598107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.528204</td>\n",
       "      <td>0.613388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.492163</td>\n",
       "      <td>0.636678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.478942</td>\n",
       "      <td>0.640483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.164700</td>\n",
       "      <td>0.683401</td>\n",
       "      <td>0.586516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>0.520355</td>\n",
       "      <td>0.619024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.787944</td>\n",
       "      <td>0.528458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.526358</td>\n",
       "      <td>0.613238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.638376</td>\n",
       "      <td>0.567677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.450666</td>\n",
       "      <td>0.626483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.556829</td>\n",
       "      <td>0.618617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.562463</td>\n",
       "      <td>0.585449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.143600</td>\n",
       "      <td>0.671039</td>\n",
       "      <td>0.583988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.706649</td>\n",
       "      <td>0.558473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.508885</td>\n",
       "      <td>0.638754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.135300</td>\n",
       "      <td>0.521517</td>\n",
       "      <td>0.627672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>0.665063</td>\n",
       "      <td>0.618200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.618300</td>\n",
       "      <td>0.613189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>0.598828</td>\n",
       "      <td>0.590741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.644400</td>\n",
       "      <td>0.598133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.625664</td>\n",
       "      <td>0.613186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.602965</td>\n",
       "      <td>0.610874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.633890</td>\n",
       "      <td>0.610681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-2948 (score: 0.6404826984976293).\n",
      "Loading module configuration from ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-2948 (score: 0.6404826984976293).\n",
      "Loading module configuration from ./training_output/checkpoint-2948/cola/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'cola'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-2948/cola/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.47894206643104553,\n",
       " 'eval_matthews_correlation': 0.6404826984976293,\n",
       " 'eval_runtime': 6.068,\n",
       " 'eval_samples_per_second': 171.885,\n",
       " 'eval_steps_per_second': 5.438}"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Io5XaCzuDlPp",
    "outputId": "b33543a4-531b-4ac8-c32c-b968564a2987"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./cola_roberta_fusion_cola/adapter_fusion_config.json\n",
      "Module weights saved in ./cola_roberta_fusion_cola/pytorch_model_adapter_fusion.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_adapter_fusion(\"./cola_roberta_fusion_cola\", \"cola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yC30zJa2pxO"
   },
   "source": [
    "**Fusion with inference tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "07a5a1431afe4fc28624031a7e9face9",
      "2a1146bc93cc46c081821974f1aebdf8",
      "b794d9c688284b28a55c754d61a8c6ec",
      "2c1348027c7047f0930df395b2b005e9",
      "5bdd1b30f78944098f47c09885c63693",
      "6ab1314915f04bdd9b97bc7cf5ca0df2",
      "5704eba7b4af4ff9aec0ee22317ca39f",
      "1938d44613e942ebba293b00c7d496d5",
      "0271276e4fb84440ac161e3096eed8ee",
      "c95ee9ac37d04e8da4b3f2d0faa13367",
      "9ca803228fb2417682f9c8e1b5a34915",
      "b349672886c445f6b0fcb8a9d56ac436",
      "1d26969a8a444109af2ed971b0fae0d3",
      "15ed695d63634d1c86fed6ba68076258",
      "f57f9ecb64ab465c859beb1b2994c1f0",
      "79cfc8b4314f4f15bd24a9b9bb4392de",
      "e02426d4ca62453e974e69bb9d30ceaa",
      "9a1e09285d0948fdb7ed99f43593ec7d",
      "caf35651bab84aca9b49ec471b6c5bf5",
      "2e824cf03d9f46cc85e9e565db46b4c5",
      "0e9234d103e14d14b5c3accd22d1f21f",
      "ae24369795a844f99c7456c61a3117b4"
     ]
    },
    "id": "riWE1xoI5i1f",
    "outputId": "cf2ef071-8f83-4c2e-c708-5de528952df5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mnli/roberta-base/pfeiffer/multinli_relu_16.zip.\n",
      "https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mnli/roberta-base/pfeiffer/multinli_relu_16.zip not found in cache or force_download set to True, downloading to /content/~/.cache/torch/adapters/tmpn5fmiqs1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a5a1431afe4fc28624031a7e9face9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mnli/roberta-base/pfeiffer/multinli_relu_16.zip in cache at ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d.76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba\n",
      "creating metadata file for ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d.76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba\n",
      "Loading module configuration from ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d-76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba-extracted/adapter_config.json\n",
      "Adding adapter 'multinli'.\n",
      "Loading module weights from ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d-76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qnli/roberta-base/pfeiffer/roberta-base_qnli_pfeiffer.zip.\n",
      "https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qnli/roberta-base/pfeiffer/roberta-base_qnli_pfeiffer.zip not found in cache or force_download set to True, downloading to /content/~/.cache/torch/adapters/tmp45eb9_hr\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b349672886c445f6b0fcb8a9d56ac436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.53M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qnli/roberta-base/pfeiffer/roberta-base_qnli_pfeiffer.zip in cache at ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa.da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c\n",
      "creating metadata file for ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa.da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c\n",
      "Loading module configuration from ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa-da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c-extracted/adapter_config.json\n",
      "Adding adapter 'qnli'.\n",
      "Loading module weights from ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa-da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c-extracted/pytorch_adapter.bin\n",
      "Some module weights could not be found in loaded weights file: roberta.invertible_adapters.qnli.F.0.weight, roberta.invertible_adapters.qnli.F.0.bias, roberta.invertible_adapters.qnli.F.2.weight, roberta.invertible_adapters.qnli.F.2.bias, roberta.invertible_adapters.qnli.G.0.weight, roberta.invertible_adapters.qnli.G.0.bias, roberta.invertible_adapters.qnli.G.2.weight, roberta.invertible_adapters.qnli.G.2.bias\n",
      "Loading module configuration from ./cola_roberta/adapter_config.json\n",
      "Adding adapter 'cola'.\n",
      "Loading module weights from ./cola_roberta/pytorch_adapter.bin\n",
      "Could not identify 'Fuse[cola, multinli, qnli]' as a valid prediction head.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.load_adapter(\"nli/multinli@ukp\", load_as=\"multinli\", with_head=False)\n",
    "model.load_adapter(\"nli/qnli@ukp\", with_head=False)\n",
    "model.load_adapter(\"./cola_roberta\", load_as=\"cola\", with_head=False)\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"cola\",\"multinli\", \"qnli\"))\n",
    "model.set_active_adapters(Fuse(\"cola\",\"multinli\", \"qnli\"))\n",
    "\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"cola\", \"multinli\", \"qnli\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4gQDvg2c5jzX",
    "outputId": "b3b121c6-b2b5-4c80-84bf-6ad0798152a3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 1:16:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.254400</td>\n",
       "      <td>0.651408</td>\n",
       "      <td>0.580345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>0.605762</td>\n",
       "      <td>0.590554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.603600</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.589491</td>\n",
       "      <td>0.605659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.693442</td>\n",
       "      <td>0.586123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.193800</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>0.598246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.578914</td>\n",
       "      <td>0.595816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.177400</td>\n",
       "      <td>0.612154</td>\n",
       "      <td>0.611204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.528716</td>\n",
       "      <td>0.621954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.489218</td>\n",
       "      <td>0.637977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.172300</td>\n",
       "      <td>0.460818</td>\n",
       "      <td>0.641021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.679797</td>\n",
       "      <td>0.579710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.521232</td>\n",
       "      <td>0.628794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.761018</td>\n",
       "      <td>0.538594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.536154</td>\n",
       "      <td>0.615759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.598345</td>\n",
       "      <td>0.587988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.450185</td>\n",
       "      <td>0.618344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.536690</td>\n",
       "      <td>0.613722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.602249</td>\n",
       "      <td>0.580891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.679990</td>\n",
       "      <td>0.571067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.711129</td>\n",
       "      <td>0.565952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.521991</td>\n",
       "      <td>0.636789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.137400</td>\n",
       "      <td>0.524909</td>\n",
       "      <td>0.620120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.132300</td>\n",
       "      <td>0.671828</td>\n",
       "      <td>0.608192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.603259</td>\n",
       "      <td>0.613388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.600191</td>\n",
       "      <td>0.636119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.130900</td>\n",
       "      <td>0.657264</td>\n",
       "      <td>0.600848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.615646</td>\n",
       "      <td>0.613211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.592467</td>\n",
       "      <td>0.611204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.122000</td>\n",
       "      <td>0.631768</td>\n",
       "      <td>0.608191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-2948 (score: 0.641021499856239).\n",
      "Loading module configuration from ./training_output/checkpoint-2948/multinli/adapter_config.json\n",
      "Overwriting existing adapter 'multinli'.\n",
      "Loading module weights from ./training_output/checkpoint-2948/multinli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-2948/multinli'\n",
      "Loading module configuration from ./training_output/checkpoint-2948/qnli/adapter_config.json\n",
      "Overwriting existing adapter 'qnli'.\n",
      "Loading module weights from ./training_output/checkpoint-2948/qnli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-2948/qnli'\n",
      "Loading module configuration from ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-2948 (score: 0.641021499856239).\n",
      "Loading module configuration from ./training_output/checkpoint-2948/cola,multinli,qnli/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'cola,multinli,qnli'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-2948/cola,multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.46081843972206116,\n",
       " 'eval_matthews_correlation': 0.641021499856239,\n",
       " 'eval_runtime': 7.6684,\n",
       " 'eval_samples_per_second': 136.012,\n",
       " 'eval_steps_per_second': 4.303}"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFrbrmaXBvHE",
    "outputId": "15839a33-c016-4d87-ffc3-e7b577933c73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./cola_roberta_fusion_nli/adapter_fusion_config.json\n",
      "Module weights saved in ./cola_roberta_fusion_nli/pytorch_model_adapter_fusion.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_adapter_fusion(\"./cola_roberta_fusion_nli\", \"cola,multinli,qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R_FftlgAfVj9",
    "outputId": "c8ef5845-8f05-413d-d708-1a8aa85ac6da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mnli/roberta-base/pfeiffer/multinli_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d-76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba-extracted/adapter_config.json\n",
      "Adding adapter 'multinli'.\n",
      "Loading module weights from ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d-76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qnli/roberta-base/pfeiffer/roberta-base_qnli_pfeiffer.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa-da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c-extracted/adapter_config.json\n",
      "Adding adapter 'qnli'.\n",
      "Loading module weights from ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa-da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c-extracted/pytorch_adapter.bin\n",
      "Some module weights could not be found in loaded weights file: roberta.invertible_adapters.qnli.F.0.weight, roberta.invertible_adapters.qnli.F.0.bias, roberta.invertible_adapters.qnli.F.2.weight, roberta.invertible_adapters.qnli.F.2.bias, roberta.invertible_adapters.qnli.G.0.weight, roberta.invertible_adapters.qnli.G.0.bias, roberta.invertible_adapters.qnli.G.2.weight, roberta.invertible_adapters.qnli.G.2.bias\n",
      "Could not identify 'Fuse[multinli, qnli]' as a valid prediction head.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.load_adapter(\"nli/multinli@ukp\", load_as=\"multinli\", with_head=False)\n",
    "model.load_adapter(\"nli/qnli@ukp\", with_head=False)\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"multinli\", \"qnli\"))\n",
    "model.set_active_adapters(Fuse(\"multinli\", \"qnli\"))\n",
    "\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"multinli\", \"qnli\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JbOPSajLfcD9",
    "outputId": "68a649ea-168e-473c-8553-af1e7aa8d01e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 1:08:42, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.520400</td>\n",
       "      <td>0.579859</td>\n",
       "      <td>0.451022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>0.639743</td>\n",
       "      <td>0.475289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.488156</td>\n",
       "      <td>0.528526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.422100</td>\n",
       "      <td>0.405054</td>\n",
       "      <td>0.576304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.409600</td>\n",
       "      <td>0.436160</td>\n",
       "      <td>0.539044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.413000</td>\n",
       "      <td>0.521209</td>\n",
       "      <td>0.500543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.433837</td>\n",
       "      <td>0.562781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.447642</td>\n",
       "      <td>0.554700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.396700</td>\n",
       "      <td>0.402070</td>\n",
       "      <td>0.566035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.381400</td>\n",
       "      <td>0.437701</td>\n",
       "      <td>0.547487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>0.458609</td>\n",
       "      <td>0.554796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.466182</td>\n",
       "      <td>0.567568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.371800</td>\n",
       "      <td>0.426214</td>\n",
       "      <td>0.572966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.370600</td>\n",
       "      <td>0.526664</td>\n",
       "      <td>0.535922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.411480</td>\n",
       "      <td>0.574317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.363600</td>\n",
       "      <td>0.517014</td>\n",
       "      <td>0.534090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.400837</td>\n",
       "      <td>0.587400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.353800</td>\n",
       "      <td>0.488707</td>\n",
       "      <td>0.572701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.343400</td>\n",
       "      <td>0.475339</td>\n",
       "      <td>0.539075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>0.512780</td>\n",
       "      <td>0.540333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.331700</td>\n",
       "      <td>0.531446</td>\n",
       "      <td>0.553315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.330200</td>\n",
       "      <td>0.465734</td>\n",
       "      <td>0.582921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.456131</td>\n",
       "      <td>0.565630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.505029</td>\n",
       "      <td>0.547117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.470999</td>\n",
       "      <td>0.562907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.492824</td>\n",
       "      <td>0.560323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.506330</td>\n",
       "      <td>0.570174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.298100</td>\n",
       "      <td>0.500360</td>\n",
       "      <td>0.562673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.482289</td>\n",
       "      <td>0.567081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>0.511683</td>\n",
       "      <td>0.555144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/multinli,qnli/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-4556 (score: 0.5874001825147708).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/multinli/adapter_config.json\n",
      "Overwriting existing adapter 'multinli'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/multinli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/multinli'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/qnli/adapter_config.json\n",
      "Overwriting existing adapter 'qnli'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/qnli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/qnli'\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-4556 (score: 0.5874001825147708).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/multinli,qnli/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'multinli,qnli'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-4556/multinli,qnli/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.4141436219215393,\n",
       " 'eval_matthews_correlation': 0.5803084401024122,\n",
       " 'eval_runtime': 6.9159,\n",
       " 'eval_samples_per_second': 150.813,\n",
       " 'eval_steps_per_second': 4.772}"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LmAdLAw3EBI"
   },
   "source": [
    "**Fusion with semantic tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tOcuAz8F3EVt",
    "outputId": "82fe4265-df46-4877-d622-0a418ee7156a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mrpc/roberta-base/pfeiffer/mrpc_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/65b70e5d16f4219a9631fd8666e3c38744ed97166c83f160ab7276df2726fd46-ee8f9fc6568ca28100c0db838b89d157df2d8faa69901a9ed3d1796e86292cd9-extracted/adapter_config.json\n",
      "Adding adapter 'mrpc'.\n",
      "Loading module weights from ~/.cache/torch/adapters/65b70e5d16f4219a9631fd8666e3c38744ed97166c83f160ab7276df2726fd46-ee8f9fc6568ca28100c0db838b89d157df2d8faa69901a9ed3d1796e86292cd9-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qqp/roberta-base/pfeiffer/qqp_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/cc572bf7d9898961547ebfe30e6d501b04c32e6a1e60ec59aaae75a18b3a3590-50448f00b5bcda4df943da413ec313f7a77c0ed75146a1a38189cd6dfffac6ca-extracted/adapter_config.json\n",
      "Adding adapter 'qqp'.\n",
      "Loading module weights from ~/.cache/torch/adapters/cc572bf7d9898961547ebfe30e6d501b04c32e6a1e60ec59aaae75a18b3a3590-50448f00b5bcda4df943da413ec313f7a77c0ed75146a1a38189cd6dfffac6ca-extracted/pytorch_adapter.bin\n",
      "Loading module configuration from ./cola_roberta/adapter_config.json\n",
      "Adding adapter 'cola'.\n",
      "Loading module weights from ./cola_roberta/pytorch_adapter.bin\n",
      "Could not identify 'Fuse[cola, mrpc, qqp]' as a valid prediction head.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.load_adapter(\"sts/mrpc@ukp\", with_head=False)\n",
    "model.load_adapter(\"sts/qqp@ukp\", with_head=False)\n",
    "model.load_adapter(\"./cola_roberta\", load_as=\"cola\", with_head=False)\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"cola\", \"mrpc\", \"qqp\"))\n",
    "model.set_active_adapters(Fuse(\"cola\", \"mrpc\", \"qqp\"))\n",
    "\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"cola\", \"mrpc\", \"qqp\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-knzIDuH3T40",
    "outputId": "ae1fcf82-42bb-4fd1-af12-b711bc50dbf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 1:17:01, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.237700</td>\n",
       "      <td>0.664197</td>\n",
       "      <td>0.540596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>0.570328</td>\n",
       "      <td>0.591175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.676242</td>\n",
       "      <td>0.552542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.673046</td>\n",
       "      <td>0.580530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.647023</td>\n",
       "      <td>0.596211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.618352</td>\n",
       "      <td>0.590554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173500</td>\n",
       "      <td>0.556364</td>\n",
       "      <td>0.578332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.608843</td>\n",
       "      <td>0.600879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.535393</td>\n",
       "      <td>0.613867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.470215</td>\n",
       "      <td>0.627978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.460145</td>\n",
       "      <td>0.624079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.683511</td>\n",
       "      <td>0.579158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>0.512187</td>\n",
       "      <td>0.619024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.772458</td>\n",
       "      <td>0.538941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>0.547913</td>\n",
       "      <td>0.605785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>0.613836</td>\n",
       "      <td>0.577848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>0.465869</td>\n",
       "      <td>0.625996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.161600</td>\n",
       "      <td>0.566514</td>\n",
       "      <td>0.625827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.580099</td>\n",
       "      <td>0.595658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.669279</td>\n",
       "      <td>0.581456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.707505</td>\n",
       "      <td>0.581456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>0.519154</td>\n",
       "      <td>0.631787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>0.516407</td>\n",
       "      <td>0.625157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.653828</td>\n",
       "      <td>0.615736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>0.620360</td>\n",
       "      <td>0.620694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.580369</td>\n",
       "      <td>0.613593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.131900</td>\n",
       "      <td>0.649312</td>\n",
       "      <td>0.600848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.612852</td>\n",
       "      <td>0.613211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.597216</td>\n",
       "      <td>0.618326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.627807</td>\n",
       "      <td>0.610703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-5896 (score: 0.6317871775012913).\n",
      "Loading module configuration from ./training_output/checkpoint-5896/mrpc/adapter_config.json\n",
      "Overwriting existing adapter 'mrpc'.\n",
      "Loading module weights from ./training_output/checkpoint-5896/mrpc/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-5896/mrpc'\n",
      "Loading module configuration from ./training_output/checkpoint-5896/qqp/adapter_config.json\n",
      "Overwriting existing adapter 'qqp'.\n",
      "Loading module weights from ./training_output/checkpoint-5896/qqp/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-5896/qqp'\n",
      "Loading module configuration from ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-5896 (score: 0.6317871775012913).\n",
      "Loading module configuration from ./training_output/checkpoint-5896/cola,mrpc,qqp/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'cola,mrpc,qqp'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-5896/cola,mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.5191537141799927,\n",
       " 'eval_matthews_correlation': 0.6317871775012913,\n",
       " 'eval_runtime': 7.6569,\n",
       " 'eval_samples_per_second': 136.217,\n",
       " 'eval_steps_per_second': 4.31}"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IEeP0W_sD3T-",
    "outputId": "6e877ade-8867-45d6-fe32-36aef8495986"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./cola_roberta_fusion_semantic/adapter_fusion_config.json\n",
      "Module weights saved in ./cola_roberta_fusion_semantic/pytorch_model_adapter_fusion.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_adapter_fusion(\"./cola_roberta_fusion_semantic\", \"cola,mrpc,qqp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a-s7g3jOfhve",
    "outputId": "af1ede96-cedb-40c5-864b-c18a0c933a3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mrpc/roberta-base/pfeiffer/mrpc_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/65b70e5d16f4219a9631fd8666e3c38744ed97166c83f160ab7276df2726fd46-ee8f9fc6568ca28100c0db838b89d157df2d8faa69901a9ed3d1796e86292cd9-extracted/adapter_config.json\n",
      "Adding adapter 'mrpc'.\n",
      "Loading module weights from ~/.cache/torch/adapters/65b70e5d16f4219a9631fd8666e3c38744ed97166c83f160ab7276df2726fd46-ee8f9fc6568ca28100c0db838b89d157df2d8faa69901a9ed3d1796e86292cd9-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qqp/roberta-base/pfeiffer/qqp_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/cc572bf7d9898961547ebfe30e6d501b04c32e6a1e60ec59aaae75a18b3a3590-50448f00b5bcda4df943da413ec313f7a77c0ed75146a1a38189cd6dfffac6ca-extracted/adapter_config.json\n",
      "Adding adapter 'qqp'.\n",
      "Loading module weights from ~/.cache/torch/adapters/cc572bf7d9898961547ebfe30e6d501b04c32e6a1e60ec59aaae75a18b3a3590-50448f00b5bcda4df943da413ec313f7a77c0ed75146a1a38189cd6dfffac6ca-extracted/pytorch_adapter.bin\n",
      "Could not identify 'Fuse[mrpc, qqp]' as a valid prediction head.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.load_adapter(\"sts/mrpc@ukp\", with_head=False)\n",
    "model.load_adapter(\"sts/qqp@ukp\", with_head=False)\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"mrpc\", \"qqp\"))\n",
    "model.set_active_adapters(Fuse(\"mrpc\", \"qqp\"))\n",
    "\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"mrpc\", \"qqp\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xCR3K5jkfm5K",
    "outputId": "d53ab60c-cd16-4ccb-94a9-9222118fd82c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 1:08:43, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>0.556513</td>\n",
       "      <td>0.422134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.453900</td>\n",
       "      <td>0.568118</td>\n",
       "      <td>0.411751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.435400</td>\n",
       "      <td>0.570202</td>\n",
       "      <td>0.419500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.429200</td>\n",
       "      <td>0.443029</td>\n",
       "      <td>0.520951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.429749</td>\n",
       "      <td>0.546908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.413900</td>\n",
       "      <td>0.561336</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.412700</td>\n",
       "      <td>0.467058</td>\n",
       "      <td>0.493805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.405700</td>\n",
       "      <td>0.444413</td>\n",
       "      <td>0.529668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.427719</td>\n",
       "      <td>0.536115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.420221</td>\n",
       "      <td>0.545606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.402900</td>\n",
       "      <td>0.416386</td>\n",
       "      <td>0.529145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.464119</td>\n",
       "      <td>0.544265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.435448</td>\n",
       "      <td>0.559840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.387700</td>\n",
       "      <td>0.513832</td>\n",
       "      <td>0.471878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.436702</td>\n",
       "      <td>0.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.384500</td>\n",
       "      <td>0.475642</td>\n",
       "      <td>0.517522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>0.399861</td>\n",
       "      <td>0.575558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.438471</td>\n",
       "      <td>0.562582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.365100</td>\n",
       "      <td>0.445742</td>\n",
       "      <td>0.544292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.361900</td>\n",
       "      <td>0.454077</td>\n",
       "      <td>0.559852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.524114</td>\n",
       "      <td>0.530413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.462047</td>\n",
       "      <td>0.558473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>0.433572</td>\n",
       "      <td>0.580349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.430906</td>\n",
       "      <td>0.568945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.347800</td>\n",
       "      <td>0.470432</td>\n",
       "      <td>0.552408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.456435</td>\n",
       "      <td>0.544269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.498196</td>\n",
       "      <td>0.541683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>0.465273</td>\n",
       "      <td>0.539044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.323300</td>\n",
       "      <td>0.462602</td>\n",
       "      <td>0.555020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>0.463696</td>\n",
       "      <td>0.552425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/mrpc,qqp/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-6164 (score: 0.5803487303998695).\n",
      "Loading module configuration from ./training_output/checkpoint-6164/mrpc/adapter_config.json\n",
      "Overwriting existing adapter 'mrpc'.\n",
      "Loading module weights from ./training_output/checkpoint-6164/mrpc/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-6164/mrpc'\n",
      "Loading module configuration from ./training_output/checkpoint-6164/qqp/adapter_config.json\n",
      "Overwriting existing adapter 'qqp'.\n",
      "Loading module weights from ./training_output/checkpoint-6164/qqp/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-6164/qqp'\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-6164 (score: 0.5803487303998695).\n",
      "Loading module configuration from ./training_output/checkpoint-6164/mrpc,qqp/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'mrpc,qqp'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-6164/mrpc,qqp/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.43799349665641785,\n",
       " 'eval_matthews_correlation': 0.5805514135255713,\n",
       " 'eval_runtime': 6.8729,\n",
       " 'eval_samples_per_second': 151.756,\n",
       " 'eval_steps_per_second': 4.801}"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsXpXMpxr__m"
   },
   "source": [
    "**Adapter Fusion with sentiment tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-yXlzhr01cpk",
    "outputId": "bed681e1-c9c2-4460-b05f-e8634aa27fe9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/sst/roberta-base/pfeiffer/sst-2_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/08bd2bd3afadb82e7742cf9dac0c8194dd11dfe87d243c801afc52c18b94cc95-c15e4812db3440398353a76fa0dd00c671157de3607fc7281e48f5d0d810ed9c-extracted/adapter_config.json\n",
      "Adding adapter 'sst_glue'.\n",
      "Loading module weights from ~/.cache/torch/adapters/08bd2bd3afadb82e7742cf9dac0c8194dd11dfe87d243c801afc52c18b94cc95-c15e4812db3440398353a76fa0dd00c671157de3607fc7281e48f5d0d810ed9c-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/imdb/roberta-base/pfeiffer/imdb_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/6ea2515baf15472203140f79c027f4efdf887c373539e55d69dfa91da127e697-5e620e059bc1bdd7dc92cf1afc9e3c64744b32ab644b215bc5be247d53e4ec10-extracted/adapter_config.json\n",
      "Adding adapter 'imdb'.\n",
      "Loading module weights from ~/.cache/torch/adapters/6ea2515baf15472203140f79c027f4efdf887c373539e55d69dfa91da127e697-5e620e059bc1bdd7dc92cf1afc9e3c64744b32ab644b215bc5be247d53e4ec10-extracted/pytorch_adapter.bin\n",
      "Loading module configuration from ./cola_roberta/adapter_config.json\n",
      "Adding adapter 'cola'.\n",
      "Loading module weights from ./cola_roberta/pytorch_adapter.bin\n",
      "Could not identify 'Fuse[cola, sst_glue, imdb]' as a valid prediction head.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.load_adapter(\"sentiment/sst-2@ukp\", with_head=False)\n",
    "model.load_adapter(\"sentiment/imdb@ukp\", with_head=False)\n",
    "model.load_adapter(\"./cola_roberta\", load_as=\"cola\", with_head=False)\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"cola\", \"sst_glue\", \"imdb\"))\n",
    "model.set_active_adapters(Fuse(\"cola\", \"sst_glue\", \"imdb\"))\n",
    "\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"cola\", \"sst_glue\", \"imdb\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qvZ30sazs3_-",
    "outputId": "0ce2641d-300f-40bc-b63f-67c4160a3d91"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 1:17:01, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.256400</td>\n",
       "      <td>0.699107</td>\n",
       "      <td>0.536329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.200500</td>\n",
       "      <td>0.598530</td>\n",
       "      <td>0.593405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.731538</td>\n",
       "      <td>0.547355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>0.511483</td>\n",
       "      <td>0.614834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.652771</td>\n",
       "      <td>0.575972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.623795</td>\n",
       "      <td>0.582996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.553577</td>\n",
       "      <td>0.563384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.612714</td>\n",
       "      <td>0.593131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.632474</td>\n",
       "      <td>0.595658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.182200</td>\n",
       "      <td>0.471716</td>\n",
       "      <td>0.632695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.483039</td>\n",
       "      <td>0.628396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.647598</td>\n",
       "      <td>0.593405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>0.519164</td>\n",
       "      <td>0.605467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.789989</td>\n",
       "      <td>0.523567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.537438</td>\n",
       "      <td>0.608192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.602891</td>\n",
       "      <td>0.572681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.164900</td>\n",
       "      <td>0.455639</td>\n",
       "      <td>0.635597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.553454</td>\n",
       "      <td>0.618897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.575878</td>\n",
       "      <td>0.582942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.644708</td>\n",
       "      <td>0.567992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.148200</td>\n",
       "      <td>0.670694</td>\n",
       "      <td>0.575972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.533603</td>\n",
       "      <td>0.628409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>0.509892</td>\n",
       "      <td>0.623762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.656576</td>\n",
       "      <td>0.610703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.141100</td>\n",
       "      <td>0.599556</td>\n",
       "      <td>0.621125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>0.576320</td>\n",
       "      <td>0.621125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.656878</td>\n",
       "      <td>0.600653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.611535</td>\n",
       "      <td>0.605677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.585435</td>\n",
       "      <td>0.618749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>0.623508</td>\n",
       "      <td>0.605767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-4556 (score: 0.6355969174067906).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/sst_glue/adapter_config.json\n",
      "Overwriting existing adapter 'sst_glue'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/sst_glue/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/sst_glue'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/imdb/adapter_config.json\n",
      "Overwriting existing adapter 'imdb'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/imdb/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/imdb'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-4556 (score: 0.6355969174067906).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola,sst_glue,imdb/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'cola,sst_glue,imdb'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.45563897490501404,\n",
       " 'eval_matthews_correlation': 0.6355969174067906,\n",
       " 'eval_runtime': 7.6861,\n",
       " 'eval_samples_per_second': 135.699,\n",
       " 'eval_steps_per_second': 4.293}"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vBZqvnZOVR5",
    "outputId": "0c053cc0-16ff-4634-9b0d-d64d5f5d88ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/sst/roberta-base/pfeiffer/sst-2_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/08bd2bd3afadb82e7742cf9dac0c8194dd11dfe87d243c801afc52c18b94cc95-c15e4812db3440398353a76fa0dd00c671157de3607fc7281e48f5d0d810ed9c-extracted/adapter_config.json\n",
      "Adding adapter 'sst_glue'.\n",
      "Loading module weights from ~/.cache/torch/adapters/08bd2bd3afadb82e7742cf9dac0c8194dd11dfe87d243c801afc52c18b94cc95-c15e4812db3440398353a76fa0dd00c671157de3607fc7281e48f5d0d810ed9c-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/imdb/roberta-base/pfeiffer/imdb_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/6ea2515baf15472203140f79c027f4efdf887c373539e55d69dfa91da127e697-5e620e059bc1bdd7dc92cf1afc9e3c64744b32ab644b215bc5be247d53e4ec10-extracted/adapter_config.json\n",
      "Adding adapter 'imdb'.\n",
      "Loading module weights from ~/.cache/torch/adapters/6ea2515baf15472203140f79c027f4efdf887c373539e55d69dfa91da127e697-5e620e059bc1bdd7dc92cf1afc9e3c64744b32ab644b215bc5be247d53e4ec10-extracted/pytorch_adapter.bin\n",
      "Could not identify 'Fuse[sst_glue, imdb]' as a valid prediction head.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.load_adapter(\"sentiment/sst-2@ukp\", with_head=False)\n",
    "model.load_adapter(\"sentiment/imdb@ukp\", with_head=False)\n",
    "#model.load_adapter(\"./cola_roberta\", load_as=\"cola\", with_head=False)\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"sst_glue\", \"imdb\"))\n",
    "model.set_active_adapters(Fuse(\"sst_glue\", \"imdb\"))\n",
    "\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"sst_glue\", \"imdb\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ahiYUJK0Oe85",
    "outputId": "66bdacce-7647-463a-f08b-0e927ffb04f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 1:08:39, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.670735</td>\n",
       "      <td>0.336241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.455500</td>\n",
       "      <td>0.496362</td>\n",
       "      <td>0.455784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.492880</td>\n",
       "      <td>0.491774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.459701</td>\n",
       "      <td>0.482939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.505807</td>\n",
       "      <td>0.477457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.579533</td>\n",
       "      <td>0.429346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.422300</td>\n",
       "      <td>0.459839</td>\n",
       "      <td>0.499220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.486993</td>\n",
       "      <td>0.502074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.456301</td>\n",
       "      <td>0.518299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.529505</td>\n",
       "      <td>0.466442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.428132</td>\n",
       "      <td>0.533899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.488916</td>\n",
       "      <td>0.482919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.446529</td>\n",
       "      <td>0.548214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.390800</td>\n",
       "      <td>0.551679</td>\n",
       "      <td>0.431516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>0.459874</td>\n",
       "      <td>0.531514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.560765</td>\n",
       "      <td>0.449570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.381300</td>\n",
       "      <td>0.403211</td>\n",
       "      <td>0.550008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.497138</td>\n",
       "      <td>0.512626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.519138</td>\n",
       "      <td>0.472246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.367200</td>\n",
       "      <td>0.555388</td>\n",
       "      <td>0.464386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.367500</td>\n",
       "      <td>0.549939</td>\n",
       "      <td>0.473195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.480556</td>\n",
       "      <td>0.518103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>0.481189</td>\n",
       "      <td>0.523333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.357400</td>\n",
       "      <td>0.465064</td>\n",
       "      <td>0.559928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.349200</td>\n",
       "      <td>0.478279</td>\n",
       "      <td>0.559928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.344100</td>\n",
       "      <td>0.497710</td>\n",
       "      <td>0.547014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>0.524009</td>\n",
       "      <td>0.541896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>0.478133</td>\n",
       "      <td>0.564981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.494046</td>\n",
       "      <td>0.559824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.329500</td>\n",
       "      <td>0.498583</td>\n",
       "      <td>0.552066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-7504 (score: 0.5649812173768567).\n",
      "Loading module configuration from ./training_output/checkpoint-7504/sst_glue/adapter_config.json\n",
      "Overwriting existing adapter 'sst_glue'.\n",
      "Loading module weights from ./training_output/checkpoint-7504/sst_glue/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-7504/sst_glue'\n",
      "Loading module configuration from ./training_output/checkpoint-7504/imdb/adapter_config.json\n",
      "Overwriting existing adapter 'imdb'.\n",
      "Loading module weights from ./training_output/checkpoint-7504/imdb/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-7504/imdb'\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-7504 (score: 0.5649812173768567).\n",
      "Loading module configuration from ./training_output/checkpoint-7504/sst_glue,imdb/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'sst_glue,imdb'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-7504/sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.4794031083583832,\n",
       " 'eval_matthews_correlation': 0.5675517176765141,\n",
       " 'eval_runtime': 6.8737,\n",
       " 'eval_samples_per_second': 151.738,\n",
       " 'eval_steps_per_second': 4.801}"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoqB1HY2sKZh"
   },
   "source": [
    "**Combine six adapters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhsCN7KMkrdM",
    "outputId": "88f071b9-ff01-462f-cca7-b6edb21578cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/sst/roberta-base/pfeiffer/sst-2_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/08bd2bd3afadb82e7742cf9dac0c8194dd11dfe87d243c801afc52c18b94cc95-c15e4812db3440398353a76fa0dd00c671157de3607fc7281e48f5d0d810ed9c-extracted/adapter_config.json\n",
      "Adding adapter 'sst_glue'.\n",
      "Loading module weights from ~/.cache/torch/adapters/08bd2bd3afadb82e7742cf9dac0c8194dd11dfe87d243c801afc52c18b94cc95-c15e4812db3440398353a76fa0dd00c671157de3607fc7281e48f5d0d810ed9c-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/imdb/roberta-base/pfeiffer/imdb_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/6ea2515baf15472203140f79c027f4efdf887c373539e55d69dfa91da127e697-5e620e059bc1bdd7dc92cf1afc9e3c64744b32ab644b215bc5be247d53e4ec10-extracted/adapter_config.json\n",
      "Adding adapter 'imdb'.\n",
      "Loading module weights from ~/.cache/torch/adapters/6ea2515baf15472203140f79c027f4efdf887c373539e55d69dfa91da127e697-5e620e059bc1bdd7dc92cf1afc9e3c64744b32ab644b215bc5be247d53e4ec10-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mnli/roberta-base/pfeiffer/multinli_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d-76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba-extracted/adapter_config.json\n",
      "Adding adapter 'multinli'.\n",
      "Loading module weights from ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d-76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qnli/roberta-base/pfeiffer/roberta-base_qnli_pfeiffer.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa-da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c-extracted/adapter_config.json\n",
      "Adding adapter 'qnli'.\n",
      "Loading module weights from ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa-da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c-extracted/pytorch_adapter.bin\n",
      "Some module weights could not be found in loaded weights file: roberta.invertible_adapters.qnli.F.0.weight, roberta.invertible_adapters.qnli.F.0.bias, roberta.invertible_adapters.qnli.F.2.weight, roberta.invertible_adapters.qnli.F.2.bias, roberta.invertible_adapters.qnli.G.0.weight, roberta.invertible_adapters.qnli.G.0.bias, roberta.invertible_adapters.qnli.G.2.weight, roberta.invertible_adapters.qnli.G.2.bias\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mrpc/roberta-base/pfeiffer/mrpc_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/65b70e5d16f4219a9631fd8666e3c38744ed97166c83f160ab7276df2726fd46-ee8f9fc6568ca28100c0db838b89d157df2d8faa69901a9ed3d1796e86292cd9-extracted/adapter_config.json\n",
      "Adding adapter 'mrpc'.\n",
      "Loading module weights from ~/.cache/torch/adapters/65b70e5d16f4219a9631fd8666e3c38744ed97166c83f160ab7276df2726fd46-ee8f9fc6568ca28100c0db838b89d157df2d8faa69901a9ed3d1796e86292cd9-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qqp/roberta-base/pfeiffer/qqp_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/cc572bf7d9898961547ebfe30e6d501b04c32e6a1e60ec59aaae75a18b3a3590-50448f00b5bcda4df943da413ec313f7a77c0ed75146a1a38189cd6dfffac6ca-extracted/adapter_config.json\n",
      "Adding adapter 'qqp'.\n",
      "Loading module weights from ~/.cache/torch/adapters/cc572bf7d9898961547ebfe30e6d501b04c32e6a1e60ec59aaae75a18b3a3590-50448f00b5bcda4df943da413ec313f7a77c0ed75146a1a38189cd6dfffac6ca-extracted/pytorch_adapter.bin\n",
      "Loading module configuration from ./cola_roberta/adapter_config.json\n",
      "Adding adapter 'cola'.\n",
      "Loading module weights from ./cola_roberta/pytorch_adapter.bin\n",
      "Could not identify 'Fuse[cola, multinli, qnli, mrpc, qqp, sst_glue, imdb]' as a valid prediction head.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.load_adapter(\"sentiment/sst-2@ukp\", with_head=False)\n",
    "model.load_adapter(\"sentiment/imdb@ukp\", with_head=False)\n",
    "model.load_adapter(\"nli/multinli@ukp\", load_as=\"multinli\", with_head=False)\n",
    "model.load_adapter(\"nli/qnli@ukp\", with_head=False)\n",
    "model.load_adapter(\"sts/mrpc@ukp\", with_head=False)\n",
    "model.load_adapter(\"sts/qqp@ukp\", with_head=False)\n",
    "model.load_adapter(\"./cola_roberta\", load_as=\"cola\", with_head=False)\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"cola\", \"multinli\", \"qnli\", \"mrpc\", \"qqp\", \"sst_glue\", \"imdb\"))\n",
    "model.set_active_adapters(Fuse(\"cola\", \"multinli\", \"qnli\", \"mrpc\", \"qqp\", \"sst_glue\", \"imdb\"))\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"cola\",\"multinli\", \"qnli\", \"mrpc\", \"qqp\", \"sst_glue\", \"imdb\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TE8C-kPAk2S-",
    "outputId": "2fcfab79-99fe-4974-8e7b-3eeae4ade16a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 1:46:36, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.548067</td>\n",
       "      <td>0.581056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.210900</td>\n",
       "      <td>0.620654</td>\n",
       "      <td>0.575804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>0.658861</td>\n",
       "      <td>0.565428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.555936</td>\n",
       "      <td>0.594786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.681526</td>\n",
       "      <td>0.570552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.210200</td>\n",
       "      <td>0.539292</td>\n",
       "      <td>0.577818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.560354</td>\n",
       "      <td>0.552549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.196100</td>\n",
       "      <td>0.611308</td>\n",
       "      <td>0.580397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.197600</td>\n",
       "      <td>0.542446</td>\n",
       "      <td>0.596883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.194900</td>\n",
       "      <td>0.506646</td>\n",
       "      <td>0.605746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.475111</td>\n",
       "      <td>0.615329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>0.666216</td>\n",
       "      <td>0.581244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.474804</td>\n",
       "      <td>0.619352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.741562</td>\n",
       "      <td>0.532799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.479663</td>\n",
       "      <td>0.630725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.635043</td>\n",
       "      <td>0.575535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.444683</td>\n",
       "      <td>0.639086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.516425</td>\n",
       "      <td>0.613069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.526683</td>\n",
       "      <td>0.588072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.152800</td>\n",
       "      <td>0.692714</td>\n",
       "      <td>0.568315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.149700</td>\n",
       "      <td>0.667267</td>\n",
       "      <td>0.575972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.509648</td>\n",
       "      <td>0.634289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.525323</td>\n",
       "      <td>0.625981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.674424</td>\n",
       "      <td>0.608191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.618323</td>\n",
       "      <td>0.613482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>0.591235</td>\n",
       "      <td>0.603931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.636473</td>\n",
       "      <td>0.605661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.613385</td>\n",
       "      <td>0.608358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.584309</td>\n",
       "      <td>0.618897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.620820</td>\n",
       "      <td>0.608449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola/head_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola/pytorch_model_head.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-4556 (score: 0.639085890464288).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/sst_glue/adapter_config.json\n",
      "Overwriting existing adapter 'sst_glue'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/sst_glue/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/sst_glue'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/imdb/adapter_config.json\n",
      "Overwriting existing adapter 'imdb'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/imdb/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/imdb'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/multinli/adapter_config.json\n",
      "Overwriting existing adapter 'multinli'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/multinli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/multinli'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/qnli/adapter_config.json\n",
      "Overwriting existing adapter 'qnli'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/qnli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/qnli'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/mrpc/adapter_config.json\n",
      "Overwriting existing adapter 'mrpc'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/mrpc/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/mrpc'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/qqp/adapter_config.json\n",
      "Overwriting existing adapter 'qqp'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/qqp/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/qqp'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola/adapter_config.json\n",
      "Overwriting existing adapter 'cola'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola/pytorch_adapter.bin\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola/head_config.json\n",
      "Overwriting existing head 'cola'\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola/pytorch_model_head.bin\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-4556 (score: 0.639085890464288).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'cola,multinli,qnli,mrpc,qqp,sst_glue,imdb'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-4556/cola,multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.44468289613723755,\n",
       " 'eval_matthews_correlation': 0.639085890464288,\n",
       " 'eval_runtime': 10.4244,\n",
       " 'eval_samples_per_second': 100.053,\n",
       " 'eval_steps_per_second': 3.166}"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ie5215tGk9Zn",
    "outputId": "6fa66bbb-ca68-4ebd-99c9-051533f98a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kzD28bEsmMdM",
    "outputId": "7e7c4fa2-e0e9-4195-9d59-eaa763c7d732"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"adapters\": {\n",
      "    \"adapters\": {},\n",
      "    \"config_map\": {}\n",
      "  },\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"2.1.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModelWithHeads: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModelWithHeads were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/sst/roberta-base/pfeiffer/sst-2_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/08bd2bd3afadb82e7742cf9dac0c8194dd11dfe87d243c801afc52c18b94cc95-c15e4812db3440398353a76fa0dd00c671157de3607fc7281e48f5d0d810ed9c-extracted/adapter_config.json\n",
      "Adding adapter 'sst_glue'.\n",
      "Loading module weights from ~/.cache/torch/adapters/08bd2bd3afadb82e7742cf9dac0c8194dd11dfe87d243c801afc52c18b94cc95-c15e4812db3440398353a76fa0dd00c671157de3607fc7281e48f5d0d810ed9c-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/imdb/roberta-base/pfeiffer/imdb_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/6ea2515baf15472203140f79c027f4efdf887c373539e55d69dfa91da127e697-5e620e059bc1bdd7dc92cf1afc9e3c64744b32ab644b215bc5be247d53e4ec10-extracted/adapter_config.json\n",
      "Adding adapter 'imdb'.\n",
      "Loading module weights from ~/.cache/torch/adapters/6ea2515baf15472203140f79c027f4efdf887c373539e55d69dfa91da127e697-5e620e059bc1bdd7dc92cf1afc9e3c64744b32ab644b215bc5be247d53e4ec10-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mnli/roberta-base/pfeiffer/multinli_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d-76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba-extracted/adapter_config.json\n",
      "Adding adapter 'multinli'.\n",
      "Loading module weights from ~/.cache/torch/adapters/a4b20be37c13e64cda7f46716bdda616abb4b396b90a61c7044244d99f5e275d-76b733dc2b30f0f82e23270b627d8237231cd7a8a90c43e2aaa6c9b6881ff1ba-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qnli/roberta-base/pfeiffer/roberta-base_qnli_pfeiffer.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa-da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c-extracted/adapter_config.json\n",
      "Adding adapter 'qnli'.\n",
      "Loading module weights from ~/.cache/torch/adapters/7fea166c43ea2b6a0b91575e85a2af9ac75f505fd65c4fce9db0009316afe1fa-da33c659efdfaac763f2bc9077cfb1559a0134e2c429bff45ee185634510d03c-extracted/pytorch_adapter.bin\n",
      "Some module weights could not be found in loaded weights file: roberta.invertible_adapters.qnli.F.0.weight, roberta.invertible_adapters.qnli.F.0.bias, roberta.invertible_adapters.qnli.F.2.weight, roberta.invertible_adapters.qnli.F.2.bias, roberta.invertible_adapters.qnli.G.0.weight, roberta.invertible_adapters.qnli.G.0.bias, roberta.invertible_adapters.qnli.G.2.weight, roberta.invertible_adapters.qnli.G.2.bias\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/mrpc/roberta-base/pfeiffer/mrpc_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/65b70e5d16f4219a9631fd8666e3c38744ed97166c83f160ab7276df2726fd46-ee8f9fc6568ca28100c0db838b89d157df2d8faa69901a9ed3d1796e86292cd9-extracted/adapter_config.json\n",
      "Adding adapter 'mrpc'.\n",
      "Loading module weights from ~/.cache/torch/adapters/65b70e5d16f4219a9631fd8666e3c38744ed97166c83f160ab7276df2726fd46-ee8f9fc6568ca28100c0db838b89d157df2d8faa69901a9ed3d1796e86292cd9-extracted/pytorch_adapter.bin\n",
      "No exactly matching adapter config found for this specifier, falling back to default.\n",
      "Resolved adapter files at https://public.ukp.informatik.tu-darmstadt.de/AdapterHub/text_task/qqp/roberta-base/pfeiffer/qqp_relu_16.zip.\n",
      "Loading module configuration from ~/.cache/torch/adapters/cc572bf7d9898961547ebfe30e6d501b04c32e6a1e60ec59aaae75a18b3a3590-50448f00b5bcda4df943da413ec313f7a77c0ed75146a1a38189cd6dfffac6ca-extracted/adapter_config.json\n",
      "Adding adapter 'qqp'.\n",
      "Loading module weights from ~/.cache/torch/adapters/cc572bf7d9898961547ebfe30e6d501b04c32e6a1e60ec59aaae75a18b3a3590-50448f00b5bcda4df943da413ec313f7a77c0ed75146a1a38189cd6dfffac6ca-extracted/pytorch_adapter.bin\n",
      "Could not identify 'Fuse[multinli, qnli, mrpc, qqp, sst_glue, imdb]' as a valid prediction head.\n",
      "Could not identify 'Fuse[multinli, qnli, mrpc, qqp, sst_glue, imdb]' as a valid prediction head.\n",
      "Adding head 'cola' with config {'head_type': 'classification', 'num_labels': 2, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'use_pooler': False, 'bias': True}.\n"
     ]
    }
   ],
   "source": [
    "config = RobertaConfig.from_pretrained(model_name, num_labels=2)\n",
    "model = RobertaModelWithHeads.from_pretrained(model_name, config=config)\n",
    "\n",
    "model.load_adapter(\"sentiment/sst-2@ukp\", with_head=False)\n",
    "model.load_adapter(\"sentiment/imdb@ukp\", with_head=False)\n",
    "model.load_adapter(\"nli/multinli@ukp\", load_as=\"multinli\", with_head=False)\n",
    "model.load_adapter(\"nli/qnli@ukp\", with_head=False)\n",
    "model.load_adapter(\"sts/mrpc@ukp\", with_head=False)\n",
    "model.load_adapter(\"sts/qqp@ukp\", with_head=False)\n",
    "#model.load_adapter(\"./cola_roberta\", load_as=\"cola\", with_head=False)\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"multinli\", \"qnli\", \"mrpc\", \"qqp\", \"sst_glue\", \"imdb\"))\n",
    "model.set_active_adapters(Fuse(\"multinli\", \"qnli\", \"mrpc\", \"qqp\", \"sst_glue\", \"imdb\"))\n",
    "\n",
    "model.add_adapter_fusion(Fuse(\"multinli\", \"qnli\", \"mrpc\", \"qqp\", \"sst_glue\", \"imdb\"))\n",
    "model.set_active_adapters(Fuse(\"multinli\", \"qnli\", \"mrpc\", \"qqp\", \"sst_glue\", \"imdb\"))\n",
    "\n",
    "model.add_classification_head(\"cola\", num_labels=2)\n",
    "\n",
    "adapter_setup = Fuse(\"multinli\", \"qnli\", \"mrpc\", \"qqp\", \"sst_glue\", \"imdb\")\n",
    "model.train_adapter_fusion(adapter_setup)\n",
    "\n",
    "trainer = create_trainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7syC_nczm9_x",
    "outputId": "bc79af4a-a652-450a-8678-a11529362b02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8551\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8040' max='8040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8040/8040 1:39:21, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.513600</td>\n",
       "      <td>0.502008</td>\n",
       "      <td>0.477767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.453400</td>\n",
       "      <td>0.554195</td>\n",
       "      <td>0.476880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.547520</td>\n",
       "      <td>0.494884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>0.414923</td>\n",
       "      <td>0.534266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.437899</td>\n",
       "      <td>0.520292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.471613</td>\n",
       "      <td>0.507304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.399800</td>\n",
       "      <td>0.451095</td>\n",
       "      <td>0.529875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.469208</td>\n",
       "      <td>0.526405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.397200</td>\n",
       "      <td>0.399254</td>\n",
       "      <td>0.535758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.390100</td>\n",
       "      <td>0.487529</td>\n",
       "      <td>0.544754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>0.433510</td>\n",
       "      <td>0.534738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>0.489893</td>\n",
       "      <td>0.531202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.370200</td>\n",
       "      <td>0.428068</td>\n",
       "      <td>0.571520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.370800</td>\n",
       "      <td>0.498726</td>\n",
       "      <td>0.523346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.391520</td>\n",
       "      <td>0.563591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.357700</td>\n",
       "      <td>0.500019</td>\n",
       "      <td>0.537483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.358600</td>\n",
       "      <td>0.402266</td>\n",
       "      <td>0.580676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.502788</td>\n",
       "      <td>0.565580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.339900</td>\n",
       "      <td>0.470689</td>\n",
       "      <td>0.559840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.345900</td>\n",
       "      <td>0.467894</td>\n",
       "      <td>0.544301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.525688</td>\n",
       "      <td>0.547514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>0.452562</td>\n",
       "      <td>0.550612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.326000</td>\n",
       "      <td>0.488171</td>\n",
       "      <td>0.557469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.461367</td>\n",
       "      <td>0.544738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.464984</td>\n",
       "      <td>0.560323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>0.474182</td>\n",
       "      <td>0.549826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.309700</td>\n",
       "      <td>0.518336</td>\n",
       "      <td>0.531514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.495332</td>\n",
       "      <td>0.555285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.476273</td>\n",
       "      <td>0.558401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.490476</td>\n",
       "      <td>0.558035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-268\n",
      "Configuration saved in ./training_output/checkpoint-268/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-268/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-268/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-536\n",
      "Configuration saved in ./training_output/checkpoint-536/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-536/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-536/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-804\n",
      "Configuration saved in ./training_output/checkpoint-804/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-804/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-804/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1072\n",
      "Configuration saved in ./training_output/checkpoint-1072/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1072/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1072/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1340\n",
      "Configuration saved in ./training_output/checkpoint-1340/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1340/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1340/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1608\n",
      "Configuration saved in ./training_output/checkpoint-1608/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1608/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1608/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-1876\n",
      "Configuration saved in ./training_output/checkpoint-1876/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-1876/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-1876/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2144\n",
      "Configuration saved in ./training_output/checkpoint-2144/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2144/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2144/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2412\n",
      "Configuration saved in ./training_output/checkpoint-2412/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2412/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2412/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2680\n",
      "Configuration saved in ./training_output/checkpoint-2680/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2680/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2680/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-2948\n",
      "Configuration saved in ./training_output/checkpoint-2948/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-2948/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-2948/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3216\n",
      "Configuration saved in ./training_output/checkpoint-3216/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3216/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3216/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3484\n",
      "Configuration saved in ./training_output/checkpoint-3484/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3484/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3484/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-3752\n",
      "Configuration saved in ./training_output/checkpoint-3752/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-3752/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-3752/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4020\n",
      "Configuration saved in ./training_output/checkpoint-4020/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4020/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4020/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4288\n",
      "Configuration saved in ./training_output/checkpoint-4288/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4288/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4288/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4556\n",
      "Configuration saved in ./training_output/checkpoint-4556/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4556/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4556/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-4824\n",
      "Configuration saved in ./training_output/checkpoint-4824/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-4824/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-4824/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5092\n",
      "Configuration saved in ./training_output/checkpoint-5092/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5092/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5092/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5360\n",
      "Configuration saved in ./training_output/checkpoint-5360/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5360/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5360/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5628\n",
      "Configuration saved in ./training_output/checkpoint-5628/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5628/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5628/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-5896\n",
      "Configuration saved in ./training_output/checkpoint-5896/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-5896/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-5896/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6164\n",
      "Configuration saved in ./training_output/checkpoint-6164/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6164/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6164/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6432\n",
      "Configuration saved in ./training_output/checkpoint-6432/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6432/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6432/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6700\n",
      "Configuration saved in ./training_output/checkpoint-6700/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6700/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6700/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-6968\n",
      "Configuration saved in ./training_output/checkpoint-6968/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-6968/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-6968/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7236\n",
      "Configuration saved in ./training_output/checkpoint-7236/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7236/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7236/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7504\n",
      "Configuration saved in ./training_output/checkpoint-7504/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7504/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7504/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-7772\n",
      "Configuration saved in ./training_output/checkpoint-7772/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-7772/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-7772/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./training_output/checkpoint-8040\n",
      "Configuration saved in ./training_output/checkpoint-8040/sst_glue/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/sst_glue/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/imdb/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/imdb/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/multinli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/multinli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qnli/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qnli/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/mrpc/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/mrpc/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/qqp/adapter_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/qqp/pytorch_adapter.bin\n",
      "Configuration saved in ./training_output/checkpoint-8040/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Module weights saved in ./training_output/checkpoint-8040/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best adapter(s) from ./training_output/checkpoint-4556 (score: 0.5806758281528572).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/sst_glue/adapter_config.json\n",
      "Overwriting existing adapter 'sst_glue'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/sst_glue/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/sst_glue'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/imdb/adapter_config.json\n",
      "Overwriting existing adapter 'imdb'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/imdb/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/imdb'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/multinli/adapter_config.json\n",
      "Overwriting existing adapter 'multinli'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/multinli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/multinli'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/qnli/adapter_config.json\n",
      "Overwriting existing adapter 'qnli'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/qnli/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/qnli'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/mrpc/adapter_config.json\n",
      "Overwriting existing adapter 'mrpc'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/mrpc/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/mrpc'\n",
      "Loading module configuration from ./training_output/checkpoint-4556/qqp/adapter_config.json\n",
      "Overwriting existing adapter 'qqp'.\n",
      "Loading module weights from ./training_output/checkpoint-4556/qqp/pytorch_adapter.bin\n",
      "No matching prediction head found in './training_output/checkpoint-4556/qqp'\n",
      "Loading best adapter fusion(s) from ./training_output/checkpoint-4556 (score: 0.5806758281528572).\n",
      "Loading module configuration from ./training_output/checkpoint-4556/multinli,qnli,mrpc,qqp,sst_glue,imdb/adapter_fusion_config.json\n",
      "Overwriting existing adapter fusion module 'multinli,qnli,mrpc,qqp,sst_glue,imdb'\n",
      "An AdapterFusion config has already been set and will NOT be overwritten\n",
      "Loading module weights from ./training_output/checkpoint-4556/multinli,qnli,mrpc,qqp,sst_glue,imdb/pytorch_model_adapter_fusion.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1043\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 30.0,\n",
       " 'eval_loss': 0.41732341051101685,\n",
       " 'eval_matthews_correlation': 0.5856159039288926,\n",
       " 'eval_runtime': 9.7584,\n",
       " 'eval_samples_per_second': 106.882,\n",
       " 'eval_steps_per_second': 3.382}"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "a-XTIOLv0isn",
    "7Mx916lBCfoL",
    "S2-2CbfPGYvi",
    "9iHhoYuLIdX3",
    "-PBgOb9L94hJ",
    "hXv2rJfrOnx-",
    "HwmHGtlw90cI"
   ],
   "name": "COLA-roberta.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01422aa981ac499ab42a2780d472fef4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_10f9f29ad5d34645abdc6d7d420449e2",
       "IPY_MODEL_4147e65bd76a47398a9796935dc9e37e",
       "IPY_MODEL_a18b73f3d7344597a0ec367ce8904b3e"
      ],
      "layout": "IPY_MODEL_c4136a59564c4e6fad94ccf6de8d2d91"
     }
    },
    "0149351d203a4325b11e362ff54695f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3f1083b462d4851bf4028e525a3a1f3",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6772c7b6fa0415a9bbfcf2c947a6870",
      "value": 456318
     }
    },
    "025962ebb1484f428fa45f030f55fecf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0271276e4fb84440ac161e3096eed8ee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "035c10c20ebf46a5a34fc7e89aaab084": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "03d8a43b86de4043b92555d85dda97bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03fb36553e7c476e9211e660d36e223e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab35a88f0fa54acfb268c3b2dafc78f1",
      "placeholder": "​",
      "style": "IPY_MODEL_051d98db5e4a465d96535220d98c15b2",
      "value": "Downloading: 100%"
     }
    },
    "051d98db5e4a465d96535220d98c15b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0696c435d3a34e90a528611216872733": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_761ea39c51d348e4920ed3909100bb79",
      "max": 5530809,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b6aabffd6d6d42f1b74e876c298b8ad1",
      "value": 5530809
     }
    },
    "07a5a1431afe4fc28624031a7e9face9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b794d9c688284b28a55c754d61a8c6ec",
       "IPY_MODEL_2c1348027c7047f0930df395b2b005e9",
       "IPY_MODEL_5bdd1b30f78944098f47c09885c63693"
      ],
      "layout": "IPY_MODEL_2a1146bc93cc46c081821974f1aebdf8"
     }
    },
    "08a4df9610774f6782677ba56ebab58e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09997ec0422642029df6971cc1a65882": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c33e7d5aba34cdfb612cb4503698109",
       "IPY_MODEL_0149351d203a4325b11e362ff54695f3",
       "IPY_MODEL_29b8234e8bfa447581b4e60a337b8140"
      ],
      "layout": "IPY_MODEL_60f6473abe214982a82859824f1995ad"
     }
    },
    "0a04dc88185d4527901b6552ffd0d7b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_557f2665e9a440b795b0dea7af31dd0d",
      "max": 1857,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de9721593e554494948ba89ff75cba34",
      "value": 1857
     }
    },
    "0e9234d103e14d14b5c3accd22d1f21f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fa462a612db4f458e7c6b64e8df4b5a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10f9f29ad5d34645abdc6d7d420449e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79039490ffb6485fb81bbf9c2400e4e8",
      "placeholder": "​",
      "style": "IPY_MODEL_afd5c79532164bc2b2d7779da2e6c415",
      "value": ""
     }
    },
    "11a2ab6d5d554369b21bf7654ceb8fd7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12692bf8d59a4deca35ddbdecfceec51": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12986320205e410c9e9eb58802cd686d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "140897f351bc419e9c135cae1a3d1166": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "144e8c60dc104f59977f611f78ac66a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_03fb36553e7c476e9211e660d36e223e",
       "IPY_MODEL_e0dbbc0fe8b847c490a2a76c125b0cbe",
       "IPY_MODEL_b7d66d2d10924e81bf0291e4d3641471"
      ],
      "layout": "IPY_MODEL_d3e4cb7567e740899e124a079e6a8c11"
     }
    },
    "15e8d4a201294c03bcec616ac5b1da84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15ed695d63634d1c86fed6ba68076258": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a1e09285d0948fdb7ed99f43593ec7d",
      "placeholder": "​",
      "style": "IPY_MODEL_e02426d4ca62453e974e69bb9d30ceaa",
      "value": "Downloading: 100%"
     }
    },
    "1938d44613e942ebba293b00c7d496d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d26969a8a444109af2ed971b0fae0d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e6160ca450e428fbb2143a682fb3434": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ef366e7d9ff4667aceacd05d51603fa",
      "placeholder": "​",
      "style": "IPY_MODEL_f52250017101446c935a42cdf56e4f97",
      "value": " 377k/377k [00:00&lt;00:00, 5.42MB/s]"
     }
    },
    "2268cd0c6fff410a99513d0ec0bffe09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f10aefb539a43a2a1b2ae3c2f037d36",
       "IPY_MODEL_8a91c2b9b68f4837805432d81c944831",
       "IPY_MODEL_2fb41cc4925b49faae22190007d6a21b"
      ],
      "layout": "IPY_MODEL_788eaced3a934c79819b095391fad060"
     }
    },
    "22747cfdd91b4f75beb7cea08049a98b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "236d318b5e294b5d90a45be919cb7b28": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2457b9477dd644bb9172920f76ae6c92": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "248136f951a545a99274a4ea556172f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26a8c094120142858b62d4c4a5578fc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfd3fed14b2f41d2a436376d8259ae70",
      "placeholder": "​",
      "style": "IPY_MODEL_5b788c8b1fa04cfa85889d879fbede28",
      "value": " 28.7k/? [00:00&lt;00:00, 978kB/s]"
     }
    },
    "29b8234e8bfa447581b4e60a337b8140": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dc894e4a3eb437db5afb0a794ca4d35",
      "placeholder": "​",
      "style": "IPY_MODEL_e3ea65c9888d45ac9ab21c6c309d6d3a",
      "value": " 456k/456k [00:00&lt;00:00, 1.55MB/s]"
     }
    },
    "2a1146bc93cc46c081821974f1aebdf8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b1ce1e1628642ebbfe6e571ad9f3407": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12986320205e410c9e9eb58802cd686d",
      "placeholder": "​",
      "style": "IPY_MODEL_b27233507a1b4fa5a7215ba01c3abf86",
      "value": "Downloading: 100%"
     }
    },
    "2c1348027c7047f0930df395b2b005e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0271276e4fb84440ac161e3096eed8ee",
      "max": 3322717,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1938d44613e942ebba293b00c7d496d5",
      "value": 3322717
     }
    },
    "2e824cf03d9f46cc85e9e565db46b4c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2edf747c338a499b8240e23161aad905": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d4f01d5693e45e2ae8e9389652b2931",
      "max": 376971,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_438beab006584f9a9612033e8771d61c",
      "value": 376971
     }
    },
    "2fb41cc4925b49faae22190007d6a21b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3232dd6917514640b583c44857b2ff23",
      "placeholder": "​",
      "style": "IPY_MODEL_7e4c1c1f1753465194b1aec5e811848c",
      "value": " 3.33M/3.33M [00:03&lt;00:00, 2.00MB/s]"
     }
    },
    "3232dd6917514640b583c44857b2ff23": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34521e8b90c5403f8bd22d498c79e329": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "35ef00dd622846279bd8f08d28ca74b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36735c3e7c40461589cbe271898c04e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ea387d97f4db4c0596afc15596259049",
       "IPY_MODEL_92475cd2561a43ed980178243eb70874",
       "IPY_MODEL_efc8b5da402e443ebe17640803915d1d"
      ],
      "layout": "IPY_MODEL_9aad2037900448adbf8dc1103c71ed1c"
     }
    },
    "38d3eebc537e4d6893276ae010581470": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3beb8070a0ef4bf195bfce6697152a4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12692bf8d59a4deca35ddbdecfceec51",
      "placeholder": "​",
      "style": "IPY_MODEL_a40cd83020454745a4ae8e83309ede06",
      "value": "Downloading: "
     }
    },
    "3d3c2023664840ad841af91c123b9e18": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d4f01d5693e45e2ae8e9389652b2931": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e1d0a98974048c3a5d3034e4a0eb3da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40d062cfa37f44ea8e1ecfc4d7075882": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c026bde83e884f13b52f0e4cc759aa8f",
      "placeholder": "​",
      "style": "IPY_MODEL_b0d4fc141fc548d5aa920b9c926a622c",
      "value": "Downloading: 100%"
     }
    },
    "4122646551fa409a812a8be07c9a184e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15e8d4a201294c03bcec616ac5b1da84",
      "max": 4473,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a3e1e6d289a4e98ab6e8ce9cf7d3d5d",
      "value": 4473
     }
    },
    "4147e65bd76a47398a9796935dc9e37e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc1c445aea0b48d19e6f89e65b34a54a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de844acc43a642bfb25f367e5abd0a43",
      "value": 1
     }
    },
    "4205dd8cbdcd4ead95daae37b707b3a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0d26e0e94c840e486436fea1827a1cb",
      "placeholder": "​",
      "style": "IPY_MODEL_a338142858c04a2ca7846f921a738adf",
      "value": "Downloading: "
     }
    },
    "421ba42a48874ef4bdc01d2ff3ed44d0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42b604dab2d64d29b10602d44c99a7f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "438beab006584f9a9612033e8771d61c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4603464810b64c70bcbb283bc53e443a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc71772258de4fb592bce57764f707c4",
      "placeholder": "​",
      "style": "IPY_MODEL_78076f7c11ba44228224d55f7e06e539",
      "value": "Downloading: 100%"
     }
    },
    "4651a1be2ad347d3b9636a7c008915e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38d3eebc537e4d6893276ae010581470",
      "placeholder": "​",
      "style": "IPY_MODEL_909b9b1535364e889084c5ca187323e2",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 5.20MB/s]"
     }
    },
    "47194bc8853b4ca4adf96f710a87e6b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d0f14c2776a4f398f2b960a6bab9e08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86c755818d1049ca971a6819438ac83a",
      "placeholder": "​",
      "style": "IPY_MODEL_42b604dab2d64d29b10602d44c99a7f7",
      "value": "Downloading: 100%"
     }
    },
    "505071ff7b1842d69af1ca5db0d740f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3beb8070a0ef4bf195bfce6697152a4f",
       "IPY_MODEL_0a04dc88185d4527901b6552ffd0d7b9",
       "IPY_MODEL_e6f0cd88d2fb4402b0a6201b9a8c21e9"
      ],
      "layout": "IPY_MODEL_03d8a43b86de4043b92555d85dda97bc"
     }
    },
    "50f0b3371e834a1591d7f70ac59e7c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b74e2bd34ee74ebb8ceb3f737d06d7bb",
       "IPY_MODEL_a5eb95fdc69643748371865f154157ad",
       "IPY_MODEL_7351c1907ef0419f80b99827b82edd3a"
      ],
      "layout": "IPY_MODEL_d2072088e73a4b83986c1a0e3ab74e41"
     }
    },
    "524ecaf8f53b483395b5645d1d74fc72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_833b18dda07a4cbeb37e8a59bafc4553",
      "placeholder": "​",
      "style": "IPY_MODEL_96d0a76b3b7f4f7d97979a182fc55945",
      "value": "Downloading: "
     }
    },
    "534615ae35a54cb7b32348c0d4c3b428": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "557f2665e9a440b795b0dea7af31dd0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56a71f4da04d41c081066809ffb7c309": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5704eba7b4af4ff9aec0ee22317ca39f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b788c8b1fa04cfa85889d879fbede28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bdd1b30f78944098f47c09885c63693": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ca803228fb2417682f9c8e1b5a34915",
      "placeholder": "​",
      "style": "IPY_MODEL_c95ee9ac37d04e8da4b3f2d0faa13367",
      "value": " 3.32M/3.32M [00:03&lt;00:00, 2.32MB/s]"
     }
    },
    "60f6473abe214982a82859824f1995ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "655ef14346da45a687a47d34ee18c70b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6702268d3a74406e8746dc12e3066a7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2b1ce1e1628642ebbfe6e571ad9f3407",
       "IPY_MODEL_ce87cd6b3b0146d996c440669a8c93ec",
       "IPY_MODEL_4651a1be2ad347d3b9636a7c008915e9"
      ],
      "layout": "IPY_MODEL_248136f951a545a99274a4ea556172f2"
     }
    },
    "69e623122e234e2882eb659c00df00d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d97b832a3f0f41bb831d5a025b7dccca",
      "placeholder": "​",
      "style": "IPY_MODEL_d82e0b341191488a8704204373f9c210",
      "value": "Downloading: 100%"
     }
    },
    "6a247d4c32544978b13871a2005581b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a61a09f496e432db1de5eadd5dc893d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_feec269c060e45d0949c5359e364c8fe",
      "placeholder": "​",
      "style": "IPY_MODEL_3d3c2023664840ad841af91c123b9e18",
      "value": ""
     }
    },
    "6ab1314915f04bdd9b97bc7cf5ca0df2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b5e7fccad2d450583789e28b143ff13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c33e7d5aba34cdfb612cb4503698109": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89a33410bc114f0e8598a468d1e59bd2",
      "placeholder": "​",
      "style": "IPY_MODEL_035c10c20ebf46a5a34fc7e89aaab084",
      "value": "Downloading: 100%"
     }
    },
    "6dc894e4a3eb437db5afb0a794ca4d35": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e734b4ab15545d3bb71e1cc12f87185": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87f9d2b4d6ad414da7c45e80b1a29b46",
      "placeholder": "​",
      "style": "IPY_MODEL_cd926cc895834ab99696560801d692ad",
      "value": " 0/0 [00:00&lt;?, ? examples/s]"
     }
    },
    "6fa88842b67e478f9c39355bebe32c30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71b2aae93c944b85af685cd0289277c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7351c1907ef0419f80b99827b82edd3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35ef00dd622846279bd8f08d28ca74b3",
      "placeholder": "​",
      "style": "IPY_MODEL_e760f211c30b4efdbc91aa8d6c230d72",
      "value": " 28.8k/? [00:00&lt;00:00, 598kB/s]"
     }
    },
    "737d6ffabe94483793795681362c90cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ad3bcb3016946c2a2ba6524ba2c7c33",
      "placeholder": "​",
      "style": "IPY_MODEL_025962ebb1484f428fa45f030f55fecf",
      "value": " 481/481 [00:00&lt;00:00, 13.3kB/s]"
     }
    },
    "761ea39c51d348e4920ed3909100bb79": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77032b279a4d49faa643c45d537a6c19": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78076f7c11ba44228224d55f7e06e539": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "788eaced3a934c79819b095391fad060": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79039490ffb6485fb81bbf9c2400e4e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79cfc8b4314f4f15bd24a9b9bb4392de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae24369795a844f99c7456c61a3117b4",
      "placeholder": "​",
      "style": "IPY_MODEL_0e9234d103e14d14b5c3accd22d1f21f",
      "value": " 5.53M/5.53M [00:03&lt;00:00, 2.97MB/s]"
     }
    },
    "7a3e1e6d289a4e98ab6e8ce9cf7d3d5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7bb05c7d061f4e5d946b3d687b0b1da3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d614be28733434e822c8c94e6afbc68",
      "placeholder": "​",
      "style": "IPY_MODEL_22747cfdd91b4f75beb7cea08049a98b",
      "value": " 7575/0 [00:00&lt;00:00, 27190.09 examples/s]"
     }
    },
    "7d614be28733434e822c8c94e6afbc68": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dbff33dab6c4b3986ec980966a32102": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e4c1c1f1753465194b1aec5e811848c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7eb8c97f48b7435884ecaac656cc0039": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7edc6b8e508f49f9a71521c425b1d222": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80d64d4715e240aa891680d9f5fbf2d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6a61a09f496e432db1de5eadd5dc893d",
       "IPY_MODEL_c11f4e959f2c4cc98134926576482148",
       "IPY_MODEL_6e734b4ab15545d3bb71e1cc12f87185"
      ],
      "layout": "IPY_MODEL_236d318b5e294b5d90a45be919cb7b28"
     }
    },
    "810c58dac58745f69bae94bff1d25ac1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e16d12ce16a8426f87e2e3ff76088526",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e06215f4f39f46b4a6724aa6ed186d79",
      "value": 1
     }
    },
    "833b18dda07a4cbeb37e8a59bafc4553": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "850e0c86d61344c4906d3668a3027f23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4205dd8cbdcd4ead95daae37b707b3a7",
       "IPY_MODEL_4122646551fa409a812a8be07c9a184e",
       "IPY_MODEL_26a8c094120142858b62d4c4a5578fc7"
      ],
      "layout": "IPY_MODEL_dab717c51b0f42898fc5db0bff734f71"
     }
    },
    "86c755818d1049ca971a6819438ac83a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86d3fabdfb7b450db687d71da95ef9fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87f9d2b4d6ad414da7c45e80b1a29b46": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89a33410bc114f0e8598a468d1e59bd2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a49edc995184c5abc8bd65aa484fb89": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a91c2b9b68f4837805432d81c944831": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11a2ab6d5d554369b21bf7654ceb8fd7",
      "max": 3327138,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b63defab5ac34420914aaa78d2b98ce0",
      "value": 3327138
     }
    },
    "8ad3bcb3016946c2a2ba6524ba2c7c33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c8a5493381041b2a52863d2ee5b0051": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_524ecaf8f53b483395b5645d1d74fc72",
       "IPY_MODEL_bf622f4a417b4c6599dd165681f94782",
       "IPY_MODEL_c2331cfc31684ad8a2eb4020227f8fd7"
      ],
      "layout": "IPY_MODEL_56a71f4da04d41c081066809ffb7c309"
     }
    },
    "8ef366e7d9ff4667aceacd05d51603fa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f10aefb539a43a2a1b2ae3c2f037d36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e1d0a98974048c3a5d3034e4a0eb3da",
      "placeholder": "​",
      "style": "IPY_MODEL_e07fd02b48484c3d83762a00723497f2",
      "value": "Downloading: 100%"
     }
    },
    "900ebdf4023d41feb5e179c75f10a1af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "909b9b1535364e889084c5ca187323e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91bc6994bb00403e95ac91c1a40b9879": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92475cd2561a43ed980178243eb70874": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a247d4c32544978b13871a2005581b8",
      "max": 3322717,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_71b2aae93c944b85af685cd0289277c3",
      "value": 3322717
     }
    },
    "92dcd66282fa453aad12ed03f1651738": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a49edc995184c5abc8bd65aa484fb89",
      "placeholder": "​",
      "style": "IPY_MODEL_534615ae35a54cb7b32348c0d4c3b428",
      "value": " 501M/501M [00:14&lt;00:00, 34.0MB/s]"
     }
    },
    "9574a1cab2ab42c788d51f1f40d1b57b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96d0a76b3b7f4f7d97979a182fc55945": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98c3500d507b466aa0d3b4a6cc740050": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9976580653bf48d8a5c556e1d84efa05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4603464810b64c70bcbb283bc53e443a",
       "IPY_MODEL_a9a4de7332ca41d39b32dd9254661b01",
       "IPY_MODEL_92dcd66282fa453aad12ed03f1651738"
      ],
      "layout": "IPY_MODEL_9574a1cab2ab42c788d51f1f40d1b57b"
     }
    },
    "9a1e09285d0948fdb7ed99f43593ec7d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9aad2037900448adbf8dc1103c71ed1c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bebfd4ce4154bbba6f59bf956585444": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9ca803228fb2417682f9c8e1b5a34915": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a18b73f3d7344597a0ec367ce8904b3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df9f8ec638df4def8c4658fbb3238aa5",
      "placeholder": "​",
      "style": "IPY_MODEL_7edc6b8e508f49f9a71521c425b1d222",
      "value": " 0/0 [00:00&lt;?, ? examples/s]"
     }
    },
    "a2b1a537be4f4d3080d4e18eb77fe111": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77032b279a4d49faa643c45d537a6c19",
      "max": 481,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_34521e8b90c5403f8bd22d498c79e329",
      "value": 481
     }
    },
    "a338142858c04a2ca7846f921a738adf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a40cd83020454745a4ae8e83309ede06": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4fe36276f554f6e82ed05271fd02736": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5eb95fdc69643748371865f154157ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_140897f351bc419e9c135cae1a3d1166",
      "max": 7777,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9bebfd4ce4154bbba6f59bf956585444",
      "value": 7777
     }
    },
    "a6507f52e92446a19f9cb6a851222010": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a960ec3f059b4bdebce9dbc60feae07b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9a4de7332ca41d39b32dd9254661b01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4fe36276f554f6e82ed05271fd02736",
      "max": 501200538,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f278e58cab344659828e21cb7d5478a6",
      "value": 501200538
     }
    },
    "ab35a88f0fa54acfb268c3b2dafc78f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae24369795a844f99c7456c61a3117b4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afd5c79532164bc2b2d7779da2e6c415": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0d4fc141fc548d5aa920b9c926a622c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b21ea221be2a4b89803e7bfd4b64aea4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86d3fabdfb7b450db687d71da95ef9fd",
      "placeholder": "​",
      "style": "IPY_MODEL_6fa88842b67e478f9c39355bebe32c30",
      "value": " 5.53M/5.53M [00:04&lt;00:00, 3.09MB/s]"
     }
    },
    "b27233507a1b4fa5a7215ba01c3abf86": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2b544a7292141bb926386efd5be9919": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b349672886c445f6b0fcb8a9d56ac436": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_15ed695d63634d1c86fed6ba68076258",
       "IPY_MODEL_f57f9ecb64ab465c859beb1b2994c1f0",
       "IPY_MODEL_79cfc8b4314f4f15bd24a9b9bb4392de"
      ],
      "layout": "IPY_MODEL_1d26969a8a444109af2ed971b0fae0d3"
     }
    },
    "b63defab5ac34420914aaa78d2b98ce0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b6aabffd6d6d42f1b74e876c298b8ad1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b74e2bd34ee74ebb8ceb3f737d06d7bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbf1694751084898933782ef82b11b54",
      "placeholder": "​",
      "style": "IPY_MODEL_c3ee78a3a0674f88acb288b03caf72a0",
      "value": "Downloading: "
     }
    },
    "b794d9c688284b28a55c754d61a8c6ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5704eba7b4af4ff9aec0ee22317ca39f",
      "placeholder": "​",
      "style": "IPY_MODEL_6ab1314915f04bdd9b97bc7cf5ca0df2",
      "value": "Downloading: 100%"
     }
    },
    "b7d66d2d10924e81bf0291e4d3641471": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d768b73cf220455f992e417b59f7dbc3",
      "placeholder": "​",
      "style": "IPY_MODEL_e3f956bacf334ed28b513f0ba3312d90",
      "value": " 899k/899k [00:00&lt;00:00, 1.60MB/s]"
     }
    },
    "bbf1694751084898933782ef82b11b54": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf622f4a417b4c6599dd165681f94782": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f26caf9ff5354b6d857095e399cb20b7",
      "max": 540,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c62be8e2ea2c4313ba0fe258109cc914",
      "value": 540
     }
    },
    "c026bde83e884f13b52f0e4cc759aa8f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c11f4e959f2c4cc98134926576482148": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d86fb42dac68454f8c1a8d1dce6e5902",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_900ebdf4023d41feb5e179c75f10a1af",
      "value": 1
     }
    },
    "c2331cfc31684ad8a2eb4020227f8fd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f54e5fb9d8a24a81af674cf1ce9a654b",
      "placeholder": "​",
      "style": "IPY_MODEL_91bc6994bb00403e95ac91c1a40b9879",
      "value": " 7.12k/? [00:00&lt;00:00, 160kB/s]"
     }
    },
    "c3ee78a3a0674f88acb288b03caf72a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4136a59564c4e6fad94ccf6de8d2d91": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5a1aa5a330e4b58af6f3fac09ce84d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7dbff33dab6c4b3986ec980966a32102",
      "placeholder": "​",
      "style": "IPY_MODEL_a6507f52e92446a19f9cb6a851222010",
      "value": ""
     }
    },
    "c62be8e2ea2c4313ba0fe258109cc914": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c95ee9ac37d04e8da4b3f2d0faa13367": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca4c8c62f8e2486f820cbb5c6d09c81d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "caf35651bab84aca9b49ec471b6c5bf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc1c445aea0b48d19e6f89e65b34a54a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "cd926cc895834ab99696560801d692ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce87cd6b3b0146d996c440669a8c93ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca4c8c62f8e2486f820cbb5c6d09c81d",
      "max": 1355863,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec57dac55cda461182c988fff726fe54",
      "value": 1355863
     }
    },
    "d0b16b61dca047fb9fb8c3f6626f9c62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_69e623122e234e2882eb659c00df00d3",
       "IPY_MODEL_0696c435d3a34e90a528611216872733",
       "IPY_MODEL_b21ea221be2a4b89803e7bfd4b64aea4"
      ],
      "layout": "IPY_MODEL_47194bc8853b4ca4adf96f710a87e6b1"
     }
    },
    "d0d26e0e94c840e486436fea1827a1cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2072088e73a4b83986c1a0e3ab74e41": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3e4cb7567e740899e124a079e6a8c11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6772c7b6fa0415a9bbfcf2c947a6870": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d768b73cf220455f992e417b59f7dbc3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d82e0b341191488a8704204373f9c210": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d86fb42dac68454f8c1a8d1dce6e5902": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d97b832a3f0f41bb831d5a025b7dccca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dab717c51b0f42898fc5db0bff734f71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc71772258de4fb592bce57764f707c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcb632c0ecb94873971f7ffaf3b81351": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5a1aa5a330e4b58af6f3fac09ce84d1",
       "IPY_MODEL_810c58dac58745f69bae94bff1d25ac1",
       "IPY_MODEL_7bb05c7d061f4e5d946b3d687b0b1da3"
      ],
      "layout": "IPY_MODEL_98c3500d507b466aa0d3b4a6cc740050"
     }
    },
    "de844acc43a642bfb25f367e5abd0a43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "de9721593e554494948ba89ff75cba34": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df9f8ec638df4def8c4658fbb3238aa5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dfd3fed14b2f41d2a436376d8259ae70": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e02426d4ca62453e974e69bb9d30ceaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e06215f4f39f46b4a6724aa6ed186d79": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e07be9e6d4b24838bb945efe16aac040": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e07fd02b48484c3d83762a00723497f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0dbbc0fe8b847c490a2a76c125b0cbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2457b9477dd644bb9172920f76ae6c92",
      "max": 898823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_655ef14346da45a687a47d34ee18c70b",
      "value": 898823
     }
    },
    "e16d12ce16a8426f87e2e3ff76088526": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "e298623774404366b574c04ee1aa1038": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d0f14c2776a4f398f2b960a6bab9e08",
       "IPY_MODEL_a2b1a537be4f4d3080d4e18eb77fe111",
       "IPY_MODEL_737d6ffabe94483793795681362c90cb"
      ],
      "layout": "IPY_MODEL_b2b544a7292141bb926386efd5be9919"
     }
    },
    "e3ea65c9888d45ac9ab21c6c309d6d3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3f1083b462d4851bf4028e525a3a1f3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3f956bacf334ed28b513f0ba3312d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6f0cd88d2fb4402b0a6201b9a8c21e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_421ba42a48874ef4bdc01d2ff3ed44d0",
      "placeholder": "​",
      "style": "IPY_MODEL_6b5e7fccad2d450583789e28b143ff13",
      "value": " 5.78k/? [00:00&lt;00:00, 129kB/s]"
     }
    },
    "e760f211c30b4efdbc91aa8d6c230d72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea387d97f4db4c0596afc15596259049": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a960ec3f059b4bdebce9dbc60feae07b",
      "placeholder": "​",
      "style": "IPY_MODEL_e07be9e6d4b24838bb945efe16aac040",
      "value": "Downloading: 100%"
     }
    },
    "ec57dac55cda461182c988fff726fe54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "efc8b5da402e443ebe17640803915d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fa462a612db4f458e7c6b64e8df4b5a",
      "placeholder": "​",
      "style": "IPY_MODEL_7eb8c97f48b7435884ecaac656cc0039",
      "value": " 3.32M/3.32M [00:03&lt;00:00, 1.65MB/s]"
     }
    },
    "f00ecbf1021d4070875a835bc30c5bf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_40d062cfa37f44ea8e1ecfc4d7075882",
       "IPY_MODEL_2edf747c338a499b8240e23161aad905",
       "IPY_MODEL_1e6160ca450e428fbb2143a682fb3434"
      ],
      "layout": "IPY_MODEL_08a4df9610774f6782677ba56ebab58e"
     }
    },
    "f26caf9ff5354b6d857095e399cb20b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f278e58cab344659828e21cb7d5478a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f52250017101446c935a42cdf56e4f97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f54e5fb9d8a24a81af674cf1ce9a654b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f57f9ecb64ab465c859beb1b2994c1f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e824cf03d9f46cc85e9e565db46b4c5",
      "max": 5530809,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_caf35651bab84aca9b49ec471b6c5bf5",
      "value": 5530809
     }
    },
    "feec269c060e45d0949c5359e364c8fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
